<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Mysql-变更datadir]]></title>
    <url>%2F2019%2F03%2F19%2Fmysql%2FMysql%E5%8F%98%E6%9B%B4datadir%2F</url>
    <content type="text"><![CDATA[变更datadir需求客户分配的虚机磁盘空间不足，又需要每天备份mysql数据 方案申请一块存储12345678910111213fdisk /dev/sdbn #新建分区1 #分区号pw #保存t #更改文件系统类型1 #选择第一个分区L ＃选择要更改的文件系统编码，可以按L来查看相关编码信息。82 #查找到linux swap的编码为82pw #保存mkfs -t ext3 /dev/sdb1mount /dev/sdb1 /data 解决办法默认安装的datadir是/var/lib/mysql,更换至/data目录下 建立/data目录 1mkdir /data 停掉MySQL进程 1mysqladmin -u root -p shutdown 把/var/lib/mysql整个目录移到/data 1mv /var/lib/mysql /data 编辑/etc/my.cnf 12datadir=/data/mysql/lib/mysqlsocket=/data/mysql/lib/mysql/mysql.sock mysql.sock软链接，很重要： 1ln -s /data/mysql/mysql.sock /var/lib/mysql/mysql.sock 启动mysqld 1systemctl restart mysqld]]></content>
      <categories>
        <category>mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mysql-使用]]></title>
    <url>%2F2019%2F01%2F03%2Fmysql%2FMysql-%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Mysql-使用查看变量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272show tables;show tables from database_name;show databases;show columns from table_name from database_name;show grants for user_name;show index from table_name;show table status;show privileges;show create database database_name;show create table table_name;show engines;show innodb status;show logs;show warnings;show errors;show [storage] engines;show variables;set global max_connections = 1000;show variables like &apos;%下面变量%&apos;max_connections 最大允许连接数1. back_log指定MySQL可能的连接数量。当MySQL主线程在很短的时间内得到非常多的连接请求，该参数就起作用，之后主线程花些时间(尽管很短)检查连接并且启动一个新线程。back_log参数的值指出在MySQL暂时停止响应新请求之前的短时间内多少个请求可以被存在堆栈中。如果系统在一个短时间内有很多连接，则需要增大该参数的值，该参数值指定到来的TCP/IP连接的侦听队列的大小。不同的操作系统在这个队列大小上有它自己的限制。 试图设定back_log高于你的操作系统的限制将是无效的。当观察MySQL进程列表，发现大量 264084 | unauthenticated user | xxx.xxx.xxx.xxx | NULL | Connect | NULL | login | NULL 的待连接进程时，就要加大 back_log 的值。back_log默认值为50。2. basedirMySQL主程序所在路径，即：--basedir参数的值。3. bdb_cache_size分配给BDB类型数据表的缓存索引和行排列的缓冲区大小，如果不使用DBD类型数据表，则应该在启动MySQL时加载 --skip-bdb 参数以避免内存浪费。4.bdb_log_buffer_size分配给BDB类型数据表的缓存索引和行排列的缓冲区大小，如果不使用DBD类型数据表，则应该将该参数值设置为0，或者在启动MySQL时加载 --skip-bdb 参数以避免内存浪费。5.bdb_home参见 --bdb-home 选项。6. bdb_max_lock指定最大的锁表进程数量(默认为10000)，如果使用BDB类型数据表，则可以使用该参数。如果在执行大型事物处理或者查询时发现 bdb: Lock table is out of available locks or Got error 12 from ... 错误，则应该加大该参数值。7. bdb_logdir指定使用BDB类型数据表提供服务时的日志存放位置。即为 --bdb-logdir 的值。8. bdb_shared_data如果使用 --bdb-shared-data 选项则该参数值为On。9. bdb_tmpdirBDB类型数据表的临时文件目录。即为 --bdb-tmpdir 的值。10. binlog_cache_size为binary log指定在查询请求处理过程中SQL 查询语句使用的缓存大小。如果频繁应用于大量、复杂的SQL表达式处理，则应该加大该参数值以获得性能提升。11. bulk_insert_buffer_size指定 MyISAM 类型数据表表使用特殊的树形结构的缓存。使用整块方式(bulk)能够加快插入操作( INSERT ... SELECT, INSERT ... VALUES (...), (...), ..., 和 LOAD DATA INFILE) 的速度和效率。该参数限制每个线程使用的树形结构缓存大小，如果设置为0则禁用该加速缓存功能。注意：该参数对应的缓存操作只能用户向非空数据表中执行插入操作!默认值为 8MB。12. character_setMySQL的默认字符集。13. character_setsMySQL所能提供支持的字符集。14. concurrent_inserts如果开启该参数，MySQL则允许在执行 SELECT 操作的同时进行 INSERT 操作。如果要关闭该参数，可以在启动 mysqld 时加载 --safe 选项，或者使用 --skip-new 选项。默认为On。15. connect_timeout指定MySQL服务等待应答一个连接报文的最大秒数，超出该时间，MySQL向客户端返回 bad handshake。16. datadir指定数据库路径。即为 --datadir 选项的值。17. delay_key_write该参数只对 MyISAM 类型数据表有效。有如下的取值种类：off: 如果在建表语句中使用 CREATE TABLE ... DELAYED_KEY_WRITES，则全部忽略DELAYED_KEY_WRITES;on: 如果在建表语句中使用 CREATE TABLE ... DELAYED_KEY_WRITES，则使用该选项(默认);all: 所有打开的数据表都将按照 DELAYED_KEY_WRITES 处理。如果 DELAYED_KEY_WRITES 开启，对于已经打开的数据表而言，在每次索引更新时都不刷新带有DELAYED_KEY_WRITES 选项的数据表的key buffer，除非该数据表关闭。该参数会大幅提升写入键值的速度。如果使用该参数，则应该检查所有数据表：myisamchk --fast --force。18.delayed_insert_limit在插入delayed_insert_limit行后，INSERT DELAYED处理模块将检查是否有未执行的SELECT语句。如果有，在继续处理前执行允许这些语句。19. delayed_insert_timeout一个INSERT DELAYED线程应该在终止之前等待INSERT语句的时间。20. delayed_queue_size为处理INSERT DELAYED分配的队列大小(以行为单位)。如果排队满了，任何进行INSERT DELAYED的客户必须等待队列空间释放后才能继续。21. flush在启动MySQL时加载 --flush 参数打开该功能。22. flush_time如果该设置为非0值，那么每flush_time秒，所有打开的表将被关，以释放资源和sync到磁盘。注意：只建议在使用 Windows9x/Me 或者当前操作系统资源严重不足时才使用该参数!23. ft_boolean_syntax搜索引擎维护员希望更改允许用于逻辑全文搜索的操作符。这些则由变量 ft_boolean_syntax 控制。24. ft_min_word_len指定被索引的关键词的最小长度。注意：在更改该参数值后，索引必须重建!25. ft_max_word_len指定被索引的关键词的最大长度。注意：在更改该参数值后，索引必须重建!26. ft_max_word_len_for_sort指定在使用REPAIR, CREATE INDEX, or ALTER TABLE等方法进行快速全文索引重建过程中所能使用的关键词的最大长度。超出该长度限制的关键词将使用低速方式进行插入。加大该参数的值，MySQL将会建立更大的临时文件(这会减轻CPU负载，但效率将取决于磁盘I/O效率)，并且在一个排序取内存放更少的键值。27. ft_stopword_file从 ft_stopword_file 变量指定的文件中读取列表。在修改了 stopword 列表后，必须重建 FULLTEXT 索引。28. have_innodbYES: MySQL支持InnoDB类型数据表; DISABLE: 使用 --skip-innodb 关闭对InnoDB类型数据表的支持。29. have_bdbYES: MySQL支持伯克利类型数据表; DISABLE: 使用 --skip-bdb 关闭对伯克利类型数据表的支持。30. have_raidYES: 使MySQL支持RAID功能。31. have_opensslYES: 使MySQL支持SSL加密协议。32. init_file指定一个包含SQL查询语句的文件，该文件在MySQL启动时将被加载，文件中的SQL语句也会被执行。33. interactive_timeout服务器在关上它前在一个交互连接上等待行动的秒数。一个交互的客户被定义为对mysql_real_connect()使用CLIENT_INTERACTIVE选项的客户。也可见wait_timeout。34. join_buffer_size用于全部联合(join)的缓冲区大小(不是用索引的联结)。缓冲区对2个表间的每个全部联结分配一次缓冲区，当增加索引不可能时，增加该值可得到一个更快的全部联结。(通常得到快速联结的最佳方法是增加索引。)35. key_buffer_size用于索引块的缓冲区大小，增加它可得到更好处理的索引(对所有读和多重写)，到你能负担得起那样多。如果你使它太大，系统将开始变慢慢。必须为OS文件系统缓存留下一些空间。为了在写入多个行时得到更多的速度。36. language用户输出报错信息的语言。37. large_file_support开启大文件支持。38. locked_in_memory使用 --memlock 将mysqld锁定在内存中。39. log记录所有查询操作。40. log_update开启update log。41. log_bin开启 binary log。42. log_slave_updates如果使用链状同步或者多台Slave之间进行同步则需要开启此参数。43. long_query_time如果一个查询所用时间超过该参数值，则该查询操作将被记录在Slow_queries中。44. lower_case_table_names1: MySQL总使用小写字母进行SQL操作;0: 关闭该功能。注意：如果使用该参数，则应该在启用前将所有数据表转换为小写字母。45. max_allowed_packet一个查询语句包的最大尺寸。消息缓冲区被初始化为net_buffer_length字节，但是可在需要时增加到max_allowed_packet个字节。该值太小则会在处理大包时产生错误。如果使用大的BLOB列，必须增加该值。46. net_buffer_length通信缓冲区在查询期间被重置到该大小。通常不要改变该参数值，但是如果内存不足，可以将它设置为查询期望的大小。(即，客户发出的SQL语句期望的长度。如果语句超过这个长度，缓冲区自动地被扩大，直到max_allowed_packet个字节。)47. max_binlog_cache_size指定binary log缓存的最大容量，如果设置的过小，则在执行复杂查询语句时MySQL会出错。48. max_binlog_size指定binary log文件的最大容量，默认为1GB。49. max_connections允许同时连接MySQL服务器的客户数量。如果超出该值，MySQL会返回Too many connections错误，但通常情况下，MySQL能够自行解决。50. max_connect_errors对于同一主机，如果有超出该参数值个数的中断错误连接，则该主机将被禁止连接。如需对该主机进行解禁，执行：FLUSH HOST;。51. max_delayed_threads不要启动多于的这个数字的线程来处理INSERT DELAYED语句。如果你试图在所有INSERT DELAYED线程在用后向一张新表插入数据，行将被插入，就像DELAYED属性没被指定那样。52. max_heap_table_size内存表所能使用的最大容量。53. max_join_size如果要查询多于max_join_size个记录的联合将返回一个错误。如果要执行没有一个WHERE的语句并且耗费大量时间，且返回上百万行的联结，则需要加大该参数值。54. max_sort_length在排序BLOB或TEXT值时使用的字节数(每个值仅头max_sort_length个字节被使用;其余的被忽略)。55. max_user_connections指定来自同一用户的最多连接数。设置为0则代表不限制。56. max_tmp_tables(该参数目前还没有作用)。一个客户能同时保持打开的临时表的最大数量。57. max_write_lock_count当出现max_write_lock_count个写入锁定数量后，开始允许一些被锁定的读操作开始执行。避免写入锁定过多，读取操作处于长时间等待状态。58. myisam_recover_options 查看连接数12show processlist; #只列出前100条show full processlist; 查看状态12345678910111213141516171819202122232425262728293031323334show status;show status like &apos;%下面变量%&apos;;Aborted_clients 由于客户没有正确关闭连接已经死掉，已经放弃的连接数量。 Aborted_connects 尝试已经失败的MySQL服务器的连接的次数。 Connections 试图连接MySQL服务器的次数。 Created_tmp_tables 当执行语句时，已经被创造了的隐含临时表的数量。 Delayed_insert_threads 正在使用的延迟插入处理器线程的数量。 Delayed_writes 用INSERT DELAYED写入的行数。 Delayed_errors 用INSERT DELAYED写入的发生某些错误(可能重复键值)的行数。 Flush_commands 执行FLUSH命令的次数。 Handler_delete 请求从一张表中删除行的次数。 Handler_read_first 请求读入表中第一行的次数。 Handler_read_key 请求数字基于键读行。 Handler_read_next 请求读入基于一个键的一行的次数。 Handler_read_rnd 请求读入基于一个固定位置的一行的次数。 Handler_update 请求更新表中一行的次数。 Handler_write 请求向表中插入一行的次数。 Key_blocks_used 用于关键字缓存的块的数量。 Key_read_requests 请求从缓存读入一个键值的次数。 Key_reads 从磁盘物理读入一个键值的次数。 Key_write_requests 请求将一个关键字块写入缓存次数。 Key_writes 将一个键值块物理写入磁盘的次数。 Max_used_connections 同时使用的连接的最大数目。 Not_flushed_key_blocks 在键缓存中已经改变但是还没被清空到磁盘上的键块。 Not_flushed_delayed_rows 在INSERT DELAY队列中等待写入的行的数量。 Open_tables 打开表的数量。 Open_files 打开文件的数量。 Open_streams 打开流的数量(主要用于日志记载） Opened_tables 已经打开的表的数量。 Questions 发往服务器的查询的数量。 Slow_queries 要花超过long_query_time时间的查询数量。 Threads_connected 当前打开的连接的数量。 Threads_running 不在睡眠的线程数量。 Uptime 服务器工作了多少秒。 mysql 按照条件导出sql1mysqldump -u root -p xxxdb --no-create-db=TRUE --no-create-info=TRUE --add-drop-table=FALSE --where=&quot;xxxx = xxx&quot; biz_appointment&gt;rs.sql; 1mysqldump -u root -p xxxdb --no-create-db=TRUE --no-create-info=TRUE --add-drop-table=FALSE -w &quot;(order_id) in (select id from biz_order where xxxxx=10067&quot; --lock-all-tables biz_order_trade &gt; rs_order_trade.sql; 忘记root密码修改MySQL的登录设置12# vi /etc/my.cnf 在[mysqld]的段中加上一句：skip-grant-tables 重新启动mysqld1service mysqld restart 登录并修改MySQL的root密码1234mysqluse mysqlupdate user set authentication_string=password(&apos;123456&apos;) where user=&apos;root&apos;;flush privileges ; 改回登录设置重新启动mysqldmysqladmin1234567891011121314151617create databasenamedrop databasenameextended-status 给出服务器的一个扩展状态消息flush-hosts 洗掉所有缓存的主机flush-logs 洗掉所有日志 flush-tables 洗掉所有表 flush-privileges 再次装载授权表(同reload) kill id,id,... 杀死mysql线程 password 新口令，将老口令改为新口令ping 检查mysqld是否活着 processlist 显示服务其中活跃线程列表reload 重载授权表 refresh 洗掉所有表并关闭和打开日志文件shutdown 关掉服务器 status 给出服务器的简短状态消息variables 打印出可用变量version 得到服务器的版本信息 第三方参照缓存一致性和跨服务器查询的数据异构解决方案canal MYSQL 学习 编译安装altas]]></content>
      <categories>
        <category>mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mysql-配置]]></title>
    <url>%2F2019%2F01%2F03%2Fmysql%2FMySQL%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[MySQL配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343[client]port = 3306socket = /tmp/mysql.sock[mysqld]port = 3306socket = /tmp/mysql.sockbasedir = /usr/local/mysqldatadir = /data/mysqlpid-file = /data/mysql/mysql.piduser = mysqlbind-address = 0.0.0.0server-id = 1 #表示是本机的序号为1,一般来讲就是master的意思skip-name-resolve# 禁止MySQL对外部连接进行DNS解析，使用这一选项可以消除MySQL进行DNS解析的时间。但需要注意，如果开启该选项，# 则所有远程主机连接授权都要使用IP地址方式，否则MySQL将无法正常处理连接请求#skip-networkingback_log = 600# MySQL能有的连接数量。当主要MySQL线程在一个很短时间内得到非常多的连接请求，这就起作用，# 然后主线程花些时间(尽管很短)检查连接并且启动一个新线程。back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。# 如果期望在一个短时间内有很多连接，你需要增加它。也就是说，如果MySQL的连接数据达到max_connections时，新来的请求将会被存在堆栈中，# 以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。# 另外，这值（back_log）限于您的操作系统对到来的TCP/IP连接的侦听队列的大小。# 你的操作系统在这个队列大小上有它自己的限制（可以检查你的OS文档找出这个变量的最大值），试图设定back_log高于你的操作系统的限制将是无效的。max_connections = 1000# MySQL的最大连接数，如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量，当然这建立在机器能支撑的情况下，因为如果连接数越多，介于MySQL会为每个连接提供连接缓冲区，就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。可以过&apos;conn%&apos;通配符查看当前状态的连接数量，以定夺该值的大小。max_connect_errors = 6000# 对于同一主机，如果有超出该参数值个数的中断错误连接，则该主机将被禁止连接。如需对该主机进行解禁，执行：FLUSH HOST。open_files_limit = 65535# MySQL打开的文件描述符限制，默认最小1024;当open_files_limit没有被配置的时候，比较max_connections*5和ulimit -n的值，哪个大用哪个，# 当open_file_limit被配置的时候，比较open_files_limit和max_connections*5的值，哪个大用哪个。table_open_cache = 128# MySQL每打开一个表，都会读入一些数据到table_open_cache缓存中，当MySQL在这个缓存中找不到相应信息时，才会去磁盘上读取。默认值64# 假定系统有200个并发连接，则需将此参数设置为200*N(N为每个连接所需的文件描述符数目)；# 当把table_open_cache设置为很大时，如果系统处理不了那么多文件描述符，那么就会出现客户端失效，连接不上max_allowed_packet = 4M# 接受的数据包大小；增加该变量的值十分安全，这是因为仅当需要时才会分配额外内存。例如，仅当你发出长查询或MySQLd必须返回大的结果行时MySQLd才会分配更多内存。# 该变量之所以取较小默认值是一种预防措施，以捕获客户端和服务器之间的错误信息包，并确保不会因偶然使用大的信息包而导致内存溢出。binlog_cache_size = 1M# 一个事务，在没有提交的时候，产生的日志，记录到Cache中；等到事务提交需要提交的时候，则把日志持久化到磁盘。默认binlog_cache_size大小32Kmax_heap_table_size = 8M# 定义了用户可以创建的内存表(memory table)的大小。这个值用来计算内存表的最大行数值。这个变量支持动态改变tmp_table_size = 16M# MySQL的heap（堆积）表缓冲大小。所有联合在一个DML指令内完成，并且大多数联合甚至可以不用临时表即可以完成。# 大多数临时表是基于内存的(HEAP)表。具有大的记录长度的临时表 (所有列的长度的和)或包含BLOB列的表存储在硬盘上。# 如果某个内部heap（堆积）表大小超过tmp_table_size，MySQL可以根据需要自动将内存中的heap表改为基于硬盘的MyISAM表。还可以通过设置tmp_table_size选项来增加临时表的大小。也就是说，如果调高该值，MySQL同时将增加heap表的大小，可达到提高联接查询速度的效果read_buffer_size = 2M# MySQL读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySQL会为它分配一段内存缓冲区。read_buffer_size变量控制这一缓冲区的大小。# 如果对表的顺序扫描请求非常频繁，并且你认为频繁扫描进行得太慢，可以通过增加该变量值以及内存缓冲区大小提高其性能read_rnd_buffer_size = 8M# MySQL的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，# MySQL会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySQL会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大sort_buffer_size = 8M# MySQL执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。# 如果不能，可以尝试增加sort_buffer_size变量的大小join_buffer_size = 8M# 联合查询操作所能使用的缓冲区大小，和sort_buffer_size一样，该参数对应的分配内存也是每连接独享thread_cache_size = 8# 这个值（默认8）表示可以重新利用保存在缓存中线程的数量，当断开连接时如果缓存中还有空间，那么客户端的线程将被放到缓存中，# 如果线程重新被请求，那么请求将从缓存中读取,如果缓存中是空的或者是新的请求，那么这个线程将被重新创建,如果有很多新的线程，# 增加这个值可以改善系统性能.通过比较Connections和Threads_created状态的变量，可以看到这个变量的作用。(–&gt;表示要调整的值)# 根据物理内存设置规则如下：# 1G —&gt; 8# 2G —&gt; 16# 3G —&gt; 32# 大于3G —&gt; 64query_cache_size = 8M#MySQL的查询缓冲大小（从4.0.1开始，MySQL提供了查询缓冲机制）使用查询缓冲，MySQL将SELECT语句和查询结果存放在缓冲区中，# 今后对于同样的SELECT语句（区分大小写），将直接从缓冲区中读取结果。根据MySQL用户手册，使用查询缓冲最多可以达到238%的效率。# 通过检查状态值&apos;Qcache_%&apos;，可以知道query_cache_size设置是否合理：如果Qcache_lowmem_prunes的值非常大，则表明经常出现缓冲不够的情况，# 如果Qcache_hits的值也非常大，则表明查询缓冲使用非常频繁，此时需要增加缓冲大小；如果Qcache_hits的值不大，则表明你的查询重复率很低，# 这种情况下使用查询缓冲反而会影响效率，那么可以考虑不用查询缓冲。此外，在SELECT语句中加入SQL_NO_CACHE可以明确表示不使用查询缓冲query_cache_limit = 2M#指定单个查询能够使用的缓冲区大小，默认1Mkey_buffer_size = 4M#指定用于索引的缓冲区大小，增加它可得到更好处理的索引(对所有读和多重写)，到你能负担得起那样多。如果你使它太大，# 系统将开始换页并且真的变慢了。对于内存在4GB左右的服务器该参数可设置为384M或512M。通过检查状态值Key_read_requests和Key_reads，# 可以知道key_buffer_size设置是否合理。比例key_reads/key_read_requests应该尽可能的低，# 至少是1:100，1:1000更好(上述状态值可以使用SHOW STATUS LIKE &apos;key_read%&apos;获得)。注意：该参数值设置的过大反而会是服务器整体效率降低ft_min_word_len = 4# 分词词汇最小长度，默认4transaction_isolation = REPEATABLE-READ# MySQL支持4种事务隔离级别，他们分别是：# READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLE.# 如没有指定，MySQL默认采用的是REPEATABLE-READ，ORACLE默认的是READ-COMMITTEDlog_bin = mysql-binbinlog_format = mixedexpire_logs_days = 30 #超过30天的binlog删除log_error = /data/mysql/mysql-error.log #错误日志路径slow_query_log = 1long_query_time = 1 #慢查询时间 超过1秒则为慢查询slow_query_log_file = /data/mysql/mysql-slow.logperformance_schema = 0explicit_defaults_for_timestamp#lower_case_table_names = 1 #不区分大小写skip-external-locking #MySQL选项以避免外部锁定。该选项默认开启default-storage-engine = InnoDB #默认存储引擎innodb_file_per_table = 1# InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间# 独立表空间优点：# 1．每个表都有自已独立的表空间。# 2．每个表的数据和索引都会存在自已的表空间中。# 3．可以实现单表在不同的数据库中移动。# 4．空间可以回收（除drop table操作处，表空不能自已回收）# 缺点：# 单表增加过大，如超过100G# 结论：# 共享表空间在Insert操作上少有优势。其它都没独立表空间表现好。当启用独立表空间时，请合理调整：innodb_open_filesinnodb_open_files = 500# 限制Innodb能打开的表的数据，如果库里的表特别多的情况，请增加这个。这个值默认是300innodb_buffer_pool_size = 64M# InnoDB使用一个缓冲池来保存索引和原始数据, 不像MyISAM.# 这里你设置越大,你在存取表里面数据时所需要的磁盘I/O越少.# 在一个独立使用的数据库服务器上,你可以设置这个变量到服务器物理内存大小的80%# 不要设置过大,否则,由于物理内存的竞争可能导致操作系统的换页颠簸.# 注意在32位系统上你每个进程可能被限制在 2-3.5G 用户层面内存限制,# 所以不要设置的太高.innodb_write_io_threads = 4innodb_read_io_threads = 4# innodb使用后台线程处理数据页上的读写 I/O(输入输出)请求,根据你的 CPU 核数来更改,默认是4# 注:这两个参数不支持动态改变,需要把该参数加入到my.cnf里，修改完后重启MySQL服务,允许值的范围从 1-64innodb_thread_concurrency = 0# 默认设置为 0,表示不限制并发数，这里推荐设置为0，更好去发挥CPU多核处理能力，提高并发量innodb_purge_threads = 1# InnoDB中的清除操作是一类定期回收无用数据的操作。在之前的几个版本中，清除操作是主线程的一部分，这意味着运行时它可能会堵塞其它的数据库操作。# 从MySQL5.5.X版本开始，该操作运行于独立的线程中,并支持更多的并发数。用户可通过设置innodb_purge_threads配置参数来选择清除操作是否使用单# 独线程,默认情况下参数设置为0(不使用单独线程),设置为 1 时表示使用单独的清除线程。建议为1innodb_flush_log_at_trx_commit = 2# 0：如果innodb_flush_log_at_trx_commit的值为0,log buffer每秒就会被刷写日志文件到磁盘，提交事务的时候不做任何操作（执行是由mysql的master thread线程来执行的。# 主线程中每秒会将重做日志缓冲写入磁盘的重做日志文件(REDO LOG)中。不论事务是否已经提交）默认的日志文件是ib_logfile0,ib_logfile1# 1：当设为默认值1的时候，每次提交事务的时候，都会将log buffer刷写到日志。# 2：如果设为2,每次提交事务都会写日志，但并不会执行刷的操作。每秒定时会刷到日志文件。要注意的是，并不能保证100%每秒一定都会刷到磁盘，这要取决于进程的调度。# 每次事务提交的时候将数据写入事务日志，而这里的写入仅是调用了文件系统的写入操作，而文件系统是有 缓存的，所以这个写入并不能保证数据已经写入到物理磁盘# 默认值1是为了保证完整的ACID。当然，你可以将这个配置项设为1以外的值来换取更高的性能，但是在系统崩溃的时候，你将会丢失1秒的数据。# 设为0的话，mysqld进程崩溃的时候，就会丢失最后1秒的事务。设为2,只有在操作系统崩溃或者断电的时候才会丢失最后1秒的数据。InnoDB在做恢复的时候会忽略这个值。# 总结# 设为1当然是最安全的，但性能页是最差的（相对其他两个参数而言，但不是不能接受）。如果对数据一致性和完整性要求不高，完全可以设为2，如果只最求性能，例如高并发写的日志服务器，设为0来获得更高性能innodb_log_buffer_size = 2M# 此参数确定些日志文件所用的内存大小，以M为单位。缓冲区更大能提高性能，但意外的故障将会丢失数据。MySQL开发人员建议设置为1－8M之间innodb_log_file_size = 32M# 此参数确定数据日志文件的大小，更大的设置可以提高性能，但也会增加恢复故障数据库所需的时间innodb_log_files_in_group = 3# 为提高性能，MySQL可以以循环方式将日志文件写到多个文件。推荐设置为3innodb_max_dirty_pages_pct = 90# innodb主线程刷新缓存池中的数据，使脏数据比例小于90%innodb_lock_wait_timeout = 120# InnoDB事务在被回滚之前可以等待一个锁定的超时秒数。InnoDB在它自己的锁定表中自动检测事务死锁并且回滚事务。InnoDB用LOCK TABLES语句注意到锁定设置。默认值是50秒bulk_insert_buffer_size = 8M# 批量插入缓存大小， 这个参数是针对MyISAM存储引擎来说的。适用于在一次性插入100-1000+条记录时， 提高效率。默认值是8M。可以针对数据量的大小，翻倍增加。myisam_sort_buffer_size = 8M# MyISAM设置恢复表之时使用的缓冲区的尺寸，当在REPAIR TABLE或用CREATE INDEX创建索引或ALTER TABLE过程中排序 MyISAM索引分配的缓冲区myisam_max_sort_file_size = 10G# 如果临时文件会变得超过索引，不要使用快速排序索引方法来创建一个索引。注释：这个参数以字节的形式给出myisam_repair_threads = 1# 如果该值大于1，在Repair by sorting过程中并行创建MyISAM表索引(每个索引在自己的线程内)interactive_timeout = 28800# 服务器关闭交互式连接前等待活动的秒数。交互式客户端定义为在mysql_real_connect()中使用CLIENT_INTERACTIVE选项的客户端。默认值：28800秒（8小时）wait_timeout = 28800# 服务器关闭非交互连接之前等待活动的秒数。在线程启动时，根据全局wait_timeout值或全局interactive_timeout值初始化会话wait_timeout值，# 取决于客户端类型(由mysql_real_connect()的连接选项CLIENT_INTERACTIVE定义)。参数默认值：28800秒（8小时）# MySQL服务器所支持的最大连接数是有上限的，因为每个连接的建立都会消耗内存，因此我们希望客户端在连接到MySQL Server处理完相应的操作后，# 应该断开连接并释放占用的内存。如果你的MySQL Server有大量的闲置连接，他们不仅会白白消耗内存，而且如果连接一直在累加而不断开，# 最终肯定会达到MySQL Server的连接上限数，这会报&apos;too many connections&apos;的错误。对于wait_timeout的值设定，应该根据系统的运行情况来判断。# 在系统运行一段时间后，可以通过show processlist命令查看当前系统的连接状态，如果发现有大量的sleep状态的连接进程，则说明该参数设置的过大，# 可以进行适当的调整小些。要同时设置interactive_timeout和wait_timeout才会生效。[mysqldump]quickmax_allowed_packet = 16M #服务器发送和接受的最大包长度[myisamchk]key_buffer_size = 8Msort_buffer_size = 8Mread_buffer = 4Mwrite_buffer = 4M]]></content>
      <categories>
        <category>mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux-网络监控]]></title>
    <url>%2F2018%2F12%2F25%2Flinux%2Fiftop%2F</url>
    <content type="text"><![CDATA[iftopTX：发送流量RX：接收流量TOTAL：总流量Cumm：运行iftop到目前时间的总流量peak：流量峰值rates：分别表示过去 2s 10s 40s 的平均流量 按h切换是否显示帮助; 按n切换显示本机的IP或主机名; 按s切换是否显示本机的host信息; 按d切换是否显示远端目标主机的host信息; 按t切换显示格式为2行/1行/只显示发送流量/只显示接收流量; 按N切换显示端口号或端口服务名称; 按S切换是否显示本机的端口信息; 按D切换是否显示远端目标主机的端口信息; 按p切换是否显示端口信息; 按P切换暂停/继续显示; 按b切换是否显示平均流量图形条; 按B切换计算2秒或10秒或40秒内的平均流量; 按T切换是否显示每个连接的总流量; 按l打开屏幕过滤功能，输入要过滤的字符，比如ip,按回车后，屏幕就只显示这个IP相关的流量信息; 按L切换显示画面上边的刻度;刻度不同，流量图形条会有变化; 按j或按k可以向上或向下滚动屏幕显示的连接记录; 按1或2或3可以根据右侧显示的三列流量数据进行排序; 按&lt;根据左边的本机名或IP排序; 按&gt;根据远端目标主机的主机名或IP排序; 按o切换是否固定只显示当前的连接; 按f可以编辑过滤代码，这是翻译过来的说法，我还没用过这个！ 按!可以使用shell命令，这个没用过！没搞明白啥命令在这好用呢！ 按q退出监控。 常用：t p n 网络配置配置网卡12345678vi /etc/sysconfig/network-scripts/ifcfg-eth0ONBOOT=yesBOOTPROTO=staticIPADDR=192.168.1.110NETMASK=255.255.255.0GATEWAY=192.168.0.1DNS1=DNS2=8.8.8.8 设置默认路由12route -nroute add default gw `grep GATEWAY /etc/sysconfig/network-scripts/ifcfg-em1 | awk -F &apos;=&apos; &apos;&#123;print $2&#125;&apos;` 添加DNS1sed -i &apos;$a nameserver 8.8.8.8&apos; /etc/resolv.conf 关闭Selinux1sed -i &apos;/SELINUX=enforcing/s/enforcing/disabled/g&apos; /etc/selinux/config]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[IDE-idea]]></title>
    <url>%2F2018%2F12%2F25%2Ftool%2FIDEA%2F</url>
    <content type="text"><![CDATA[IDEA快捷键显示当前类的层次结构⌃H(control + H) 显示方法层次结构⌘⇧H(common+shift+h) 显示调用层次结构⌃⌥H(control+alt+h) 复制行⌘D 自动代码可以显示当前文件的结构⌘F12 类图⌘⌥U 插件]]></content>
      <categories>
        <category>tool</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux-内核调优]]></title>
    <url>%2F2018%2F12%2F24%2Flinux%2F%E5%86%85%E6%A0%B8%E8%B0%83%E4%BC%98sysctl.conf%2F</url>
    <content type="text"><![CDATA[内核调优sysctl.confnet.ipv4.tcp_syncookies = 1表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭； net.ipv4.tcp_tw_reuse = 1表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭； net.ipv4.tcp_tw_recycle = 1表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭； net.ipv4.tcp_fin_timeout = 30修改系統默认的 TIMEOUT 时间 net.ipv4.tcp_keepalive_time = 1200表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。 net.ipv4.ip_local_port_range = 10000 65000表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为10000到65000。（注意：这里不要将最低值设的太低，否则可能会占用掉正常的端口！） net.ipv4.tcp_max_syn_backlog = 8192表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。 net.ipv4.tcp_max_tw_buckets = 6000表示系统同时保持TIME_WAIT的最大数量，如果超过这个数字，TIME_WAIT将立刻被清除并打印警告信息。默 认为180000，改为6000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT的最大数量，避免Squid服务器被大量的TIME_WAIT拖死。 net.ipv4.tcp_max_syn_backlog = 65536记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M内存的系统而言，缺省值是1024，小内存的系统则是128。 net.core.netdev_max_backlog = 32768每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。 net.core.somaxconn = 32768web应用中listen函数的backlog默认会给我们内核参数的net.core.somaxconn限制到128，而nginx定义的NGX_LISTEN_BACKLOG默认为511，所以有必要调整这个值。 net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216 最大socket读buffer,可参考的优化值:873200net.core.wmem_max = 16777216 最大socket写buffer,可参考的优化值:873200net.ipv4.tcp_timestsmps = 0时间戳可以避免序列号的卷绕。一个1Gbps的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。 net.ipv4.tcp_synack_retries = 2为了打开对端的连接，内核需要发送一个SYN并附带一个回应前面一个SYN的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK包的数量。 net.ipv4.tcp_syn_retries = 2在内核放弃建立连接之前发送SYN包的数量。 #net.ipv4.tcp_tw_len = 1net.ipv4.tcp_tw_reuse = 1 开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接。 net.ipv4.tcp_wmem = 8192 436600 873200TCP写buffer,可参考的优化值: 8192 436600 873200 net.ipv4.tcp_rmem = 32768 436600 873200TCP读buffer,可参考的优化值: 32768 436600 873200 net.ipv4.tcp_mem = 94500000 91500000 92700000 同样有3个值,意思是:net.ipv4.tcp_mem[0]:低于此值，TCP没有内存压力。net.ipv4.tcp_mem[1]:在此值下，进入内存压力阶段。net.ipv4.tcp_mem[2]:高于此值，TCP拒绝分配socket。上述内存单位是页，而不是字节。可参考的优化值是:786432 1048576 1572864 net.ipv4.tcp_max_orphans = 3276800系统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，连接将即刻被复位并打印出警告信息。这个限制仅仅是为了防止简单的DoS攻击，不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。 net.ipv4.tcp_fin_timeout = 30如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60秒。2.2 内核的通常值是180秒，你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB服务器，也有因为大量的死套接字而内存溢出的风险，FIN- WAIT-2的危险性比FIN-WAIT-1要小，因为它最多只能吃掉1.5K内存，但是它们的生存期长些。 DOS和DDOS原理假冒的IP发来海量的请求连接的第一个握手包（SYN包），被攻击服务器回应第二个握手包（SYN+ACK包），因为对方是假冒IP，对方永远收不到包且不会回应第三个握手包。导致被攻击服务器保持大量SYN_RECV状态的“半连接” 应急处理netstat -na&gt;net.lognetstat -na |grep SYN_RECV|moreiptables -A INPUT -s 173.0.0.0/8 -p tcp –dport 80 -j DROP 使用F5挡攻击,中转一层让客户端先和F5三次握手，连接建立之后F5才转发到后端业务服务器 调整系统参数挡攻击tcp_synack_retries = 0不重试，默认重试5次net.ipv4.tcp_max_syn_backlog = 200000 实践123456789101112131415161718192021222324252627282930sysctl -a | grep net.ipv4.tcp_tw_reusevi /etc/sysctl.confnet.ipv4.ip_forward = 0net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296vm.swappiness = 0net.ipv4.neigh.default.gc_stale_time=120net.ipv4.conf.all.rp_filter=0net.ipv4.conf.default.rp_filter=0net.ipv4.conf.default.arp_announce = 2net.ipv4.conf.all.arp_announce=2net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn_backlog = 8192net.ipv4.tcp_synack_retries = 2net.ipv4.conf.lo.arp_announce=2net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_fin_timeout = 30sysctl -psysctl -a | grep net.ipv4.tcp_tw_reuse]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java-时间复杂度]]></title>
    <url>%2F2018%2F12%2F22%2FJVM%2F%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[时间复杂度时间复杂度说明 复杂度 标记符号 描述 常量 O(1) 操作的数量为常数，与输入的数据的规模无关。 对数 O(log2 n) 操作的数量与输入数据的规模 n 的比例是 log2 (n),当n=8，log2(8)=3即2的立方=8，以10为底的对数简写做 lg N 线性 O(n) 操作的数量与输入数据的规模 n 成正比 平方 O(n2) 操作的数量与输入数据的规模 n 的比例为二次平方 立方 O(n3) 指数 O(2n) O(kn) O(n!) 指数级的操作，快速的增长 时间复杂度与运行时间 复杂度 1000 10000 100000 O(1) &lt;1s &lt;1s &lt;1s O(log2(n)) &lt;1s &lt;1s &lt;1s O(n) &lt;1s &lt;1s &lt;1s (n*log2(n)) &lt;1s &lt;1s &lt;1s O(n2) &lt;1s 2s 3-4 min O(n3) 20s 5 hours 231 days ps:循环1 &lt;&lt; n，时间复杂度为 2的n次方]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mysql-隔离级别]]></title>
    <url>%2F2018%2F12%2F14%2Fmysql%2F%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Mysql隔离级别场景一：B事务update 未commit场景二：B事务update commit场景三：B事务insert commit，A事务commit read-uncommit：一：A事务select出update后结果。脏读！不可重复读！幻读！ read-commit：一：A事务select出update前结果。不脏读。二：A事务select出update后结果。不可重复读！幻读！ repeatable-read:一：A事务select出update前结果。不脏读。二：A事务select出update前结果。可重复读。三：突然多出一条记录。幻读！原理：使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。 serializable:B事务insert 失败！原理：锁表 小结：不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表]]></content>
      <categories>
        <category>mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[tool-brew]]></title>
    <url>%2F2018%2F12%2F12%2Ftool%2FHomebrew%2F</url>
    <content type="text"><![CDATA[Homebrew安装 Tomcat1brew install tomcat 安装的是最新版的版本 卸载 Tomcat1brew uninstall tomcat 更新1brew upgrade tomcat 更新不会删除原来的，相当于重新安装一个最新版，也就是说配置不能共用 切换版本1brew switch tomcat 8.5.4 升级会出现几个不同版本的 Tomcat 同时存在，切换到指定的版本就很有必要了卸载 卸载全部旧版本1brew cleanup tomcat 卸载当前版本1brew remove tomcat 卸载全部版本1brew uninstall --force tomcat 卸载指定版本12brew switch tomcat 8.5.4brew remove tomcat 查看已安装的 Tomcat 的版本和最新的版本信息1brew info tomcat 查看可安装的 Tomcat 的所有版本1brew search tomcat 输出:homebrew/versions/tomcat6homebrew/versions/tomcat7tomcattomcat-native 安装指定版本的 Tomcat，例如 tomcat61brew install homebrew/versions/tomcat6 列出已经安装的软件1brew list 查看 brew 的帮助1man brew 列出所有安装的软件里可以升级的1brew outdated 清理不需要的版本极其安装包缓存1brew cleanup]]></content>
      <categories>
        <category>mac</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[spring boot-启动]]></title>
    <url>%2F2018%2F11%2F29%2Fspring%2Fspring%20boot-%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[spring boot-启动启动原理1234567891011121314151617181920212223242526* SpringBootApplication* 0. ComponetScan* EnableAutoConfiguration* AutoConfigurationPackage* Import(AutoConfigurationImportSelector.class)-&gt;spring.factores* Conifuration* ConditionalOnClass* ConditionalOnProperty* run* 1. new SpringApplication* create ApplicationContext* SpringFactoriesLoader load ApplicationContextInitializer* SpringFactoriesLoader load ApplicationListener* main* 2. for **ApplicationRunListener.started()*** 3. init Environment* 4. **ApplicationRunListener.environmentPrepared()*** 5. sout banner* 6. ApplicationContextClass.setEnviroment(env) (ShutdownHook BeanNameGenerator ResourceLoader)* 7. SpringFactoriesLoader ApplicationContextInitializer.initialize()* 8. **ApplicationRunListener.contextPrepared()*** 9. 0-&gt;ApplicationContext* 10. **ApplicationRunListener.contextLoaded()*** 11. ApplicationContext.refresh()* 12. CommandLineRunner* 13. **ApplicationRunListener.finished()** 扫描所有configuration类和spring.factores中定义的初始化类 创建applicationContext，springFactoriesLoader load Initializer 和 applicationLister applicationRunLister -&gt; started 初始化 环境变量 applicationRunLister -&gt; environmentPrepared 设置环境变量到applicationContext spring boot warbuild.gradle123456apply plugin: 'war'compile("org.springframework.boot:spring-boot-starter-web:$&#123;springBootVersion&#125;") &#123; exclude module:"spring-boot-starter-tomcat"&#125;compile("javax.servlet:javax.servlet-api:3.1.0")compile("org.apache.tomcat:tomcat-servlet-api:8.0.36") Application.java1234567891011121314151617public class Application extends SpringBootServletInitializer &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; /** *重写configure * @param builder * @return */ @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(Application.class); &#125;&#125; SpringMVC处理流程 用户发送请求至前端控制器DispatcherServlet。 DispatcherServlet收到请求调用HandlerMapping处理器映射器。 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。 DispatcherServlet调用HandlerAdapter处理器适配器。 HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。 Controller执行完成返回ModelAndView。 HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。 DispatcherServlet将ModelAndView传给ViewReslover视图解析器。 ViewReslover解析后返回具体View。 DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。 DispatcherServlet响应用户。]]></content>
      <categories>
        <category>spring</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java-JVM调优]]></title>
    <url>%2F2018%2F11%2F20%2FJVM%2FJVM%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[JVM调优基础知识： 基本数据类型，堆对象的引用，程序存储在栈中，方法以先进后出进栈，栈的起点是main方法一个线程对应一个栈空间，栈是运行单元，栈调优参数：-Xss，StackOverFlowError是栈中死循环无法返回递归。 对象存储在堆中，堆是存储单元。堆调优参数：-Xms 垃圾回收算法 引用计数：增加一个对象引用，计数加1，减少一个对象引用，计数减1，计数为0 回收，问题：循环引用无法回收 标记-清除：第一阶段从根节点开始标记对象引用，第二阶段未标记的对象清除。问题：空间碎片 复制：两块内存，复制正在使用对象到另外一块内存空间。问题：两倍空间 标记-整理：第一阶段从根节点开始标记对象引用，第二阶段未标记的对象清除同时整理存活对象到清除的对象空间上 分代回收不同对象有不同的生命周期（人也如此），session，socket等需要长周期，String 这种不变类需要短周期 分代： 年轻代（Eden，survivor），有意思的命名！Eden：伊甸园，亚当夏娃居住地。survivor：幸存者 年老代， 持久代（方法区），java.lang.OutOfMemoryError: PermGen space，调优参数：-XX:MaxPermSize。调优经验：问题描述：thrift定义了大量big class，尽管以及做了生产环境1024M的调优，但依旧出现PerGen space错误。解决办法：升级到jdk8。原理：因为jdk8已经元空间代替持久代，metaspace占用本地内存，不占用虚拟机内存。 GC类型 scavenge（搜索） GC：主要作用于年轻代，高频清理Eden，采用并行收集器，调优参数：XX:+UseParallelGC full GC 配置参数 -Xmx：JVM最大可用内存 -Xms：JVM初始内存，设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存 -Xmn：年轻代内存 -Xss：]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[面试题-持续更新]]></title>
    <url>%2F2018%2F11%2F16%2Fother%2F%E9%9D%A2%E8%AF%95%E9%A2%98-%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[面试题-持续更新一、Java基础Collections.sort()方法写一个类，继承AtomicLong，再写一个setIfGreater方法，如果新值比旧值大就替换，要求无锁并线程安全。实现一个LinkedMultiValueMap类，一个key对应多个value（value可以存储List），需要实现add方法，set方法，get方法，put方法等。要求无锁并线程安全。举例说明Spring框架的异步servlet。Java阻塞队列ArrayBlockingQueue和LinkedBlockingQueue实现原理分析 二、Java多线程线程池的原理，为什么要创建线程池？创建线程池的方式；线程的生命周期，什么时候会出现僵死进程；说说线程安全问题，什么实现线程安全，如何实现线程安全；创建线程池有哪几个核心参数？ 如何合理配置线程池的大小？volatile、ThreadLocal的使用场景和原理；ThreadLocal什么时候会出现OOM的情况？为什么？synchronized、volatile区别、synchronized锁粒度、模拟死锁场景、原子性与可见性； 三、JVM相关JVM内存模型，GC机制和原理；GC分哪两种，Minor GC 和Full GC有什么区别？什么时候会触发Full GC？分别采用什么算法？JVM里的有几种classloader，为什么会有多种？什么是双亲委派机制？介绍一些运作过程，双亲委派模型的好处；什么情况下我们需要破坏双亲委派模型；常见的JVM调优方法有哪些？可以具体到调整哪个参数，调成什么值？JVM虚拟机内存划分、类加载器、垃圾收集算法、垃圾收集器、class文件结构是如何解析的；java 查看GC日志，如何计算 allocation rate 和 promotion rate 四、Java扩展篇红黑树的实现原理和应用场景；NIO是什么？适用于何种场景？Java9比Java8改进了什么；HashMap内部的数据结构是什么？底层是怎么实现的？（还可能会延伸考察ConcurrentHashMap与HashMap、HashTable等，考察对技术细节的深入了解程度）；说说反射的用途及实现，反射是不是很慢，我们在项目中是否要避免使用反射；说说自定义注解的场景及实现；List 和 Map 区别，Arraylist 与 LinkedList 区别，ArrayList 与 Vector 区别； 五、Spring相关Spring AOP的实现原理和场景？Spring bean的作用域和生命周期；Spring Boot比Spring做了哪些改进？ Spring 5比Spring4做了哪些改进；如何自定义一个Spring Boot Starter？Spring IOC是什么？优点是什么？SpringMVC、动态代理、反射、AOP原理、事务隔离级别； 六、中间件篇Dubbo完整的一次调用链路介绍；Dubbo支持几种负载均衡策略？Dubbo Provider服务提供者要控制执行并发请求上限，具体怎么做？Dubbo启动的时候支持几种配置方式？了解几种消息中间件产品？各产品的优缺点介绍；消息中间件如何保证消息的一致性和如何进行消息的重试机制？Spring Cloud熔断机制介绍；Spring Cloud对比下Dubbo，什么场景下该使用Spring Cloud？ 七、数据库篇锁机制介绍：行锁、表锁、排他锁、共享锁；乐观锁的业务场景及实现方式；事务介绍，分布式事物的理解，常见的解决方案有哪些，什么事两阶段提交、三阶段提交；MySQL记录binlog的方式主要包括三种模式？每种模式的优缺点是什么？MySQL锁，悲观锁、乐观锁、排它锁、共享锁、表级锁、行级锁；分布式事务的原理2阶段提交，同步异步阻塞非阻塞；数据库事务隔离级别，MySQL默认的隔离级别、Spring如何实现事务、JDBC如何实现事务、嵌套事务实现、分布式事务实现；SQL的整个解析、执行过程原理、SQL行转列；mysql语句优化 八、RedisRedis为什么这么快？redis采用多线程会有哪些问题？Redis支持哪几种数据结构；Redis跳跃表的问题；Redis单进程单线程的Redis如何能够高并发?Redis如何使用Redis实现分布式锁？Redis分布式锁操作的原子性，Redis内部是如何实现的？ 九、监控CPUCPU负载：监控CPU一段时间内负载平均值CPU数量：监控CPU在线或者最大数量CPU利用率：监控一段时间内CPU的idle，nice，userCPU信息：监测CPU相关信息，如频率 内存内存总大小内存使用量剩余内存内存缓存 swap从设备到内存统计从内存到设备统计交换空间大小 磁盘磁盘读取统计信息磁盘写入统计磁盘空间 进程进程CPU利用率百分比用户进程使用内存进程数量 网络网络接口列表网卡流入量统计网卡流出量统计 TCPTCP状态 十、数据结构与算法二叉树红黑树 十一、架构反向代理方面，nginx的基本配置，比如如何通过lua语言设置规则，如何设置session粘滞。如果可以，再看些nginx的底层，比如协议，集群设置，失效转移等。 远程调用dubbo方面，可以看下dubbo和zookeeper整合的知识点，再深一步，了解下dubbo底层的传输协议和序列化方式。 消息队列方面，可以看下kafka或任意一种组件的使用方式，简单点可以看下配置，工作组的设置，再深入点，可以看下Kafka集群，持久化的方式，以及发送消息是用长连接还是短拦截。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s集群安装]]></title>
    <url>%2F2018%2F10%2F11%2Fk8s%2Fk8s%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[k8s集群部署master准备阶段12345678hostnamectl --static set-hostname mastervi /etc/hostsapt-get updateapt-get install firewalld -ysystemctl stop firewalldapt install selinux-utils -ysetenforce 0swapoff -a vi /etc/sysctl.conf1net.ipv4.ip_forward = 1 sysctl -p vi /etc/docker/daemon.json123&#123; &quot;iptables&quot;: false&#125; 123456sudo tee /etc/sysctl.d/k8s.conf &lt;&lt;-&apos;EOF&apos;net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsudo sysctl --system docker 安装123456789101112131415# 安装包允许apt通过HTTPS使用仓库1. apt-get install -y apt-transport-https ca-certificates curl software-properties-common# 添加Docker官方GPG key2. curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -# 设置Docker稳定版仓库3. add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"4. add-apt-repository "deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main"5. apt-get update# 安装Docker CE（社区版）6. apt-get install -y docker-ce=17.03.2~ce-0~ubuntu-xenial 安装kubeadm1apt-get install -y kubelet=1.10.3-00 kubeadm=1.10.3-00 kubectl=1.10.3-00 --allow-unauthenticated 12apt-cache madison kubeadmapt-get remove -y kubelet kubeadm kubectl kubeadm初始化集群国内镜像1234567#!/bin/bashimages=(kube-proxy-amd64:v1.10.3 kube-scheduler-amd64:v1.10.3 kube-controller-manager-amd64:v1.10.3 kube-apiserver-amd64:v1.10.3 etcd-amd64:3.1.12 pause-amd64:3.1 k8s-dns-sidecar-amd64:1.14.8 k8s-dns-kube-dns-amd64:1.14.8 k8s-dns-dnsmasq-nanny-amd64:1.14.8)for imageName in $&#123;images[@]&#125; ; do docker pull anjia0532/$imageName docker tag anjia0532/$imageName k8s.gcr.io/$imageName docker rmi anjia0532/$imageNamedone 123创建/etc/sysctl.d/k8s.conf文件，添加如下内容：net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1 初始化集群1kubeadm init --kubernetes-version 1.10.3 --apiserver-advertise-address=172.xx.xxx.xx --pod-network-cidr=10.244.0.0/16 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 生成如下串，请记录下来1kubeadm join 172.xx.xxx.xx:6443 --token xxxxxx --discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxx 1234kubectl get nodekubectl get pod --all-namespaceskubectl create -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel-rbac.ymlkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 123heapsterkubectl create -f http://res.yinnote.com/kubernetes/heapster/1.5.1/heapster-rbac.yamlkubectl create -f http://res.yinnote.com/kubernetes/heapster/1.5.1/influxdb/heapster.yaml kubernetes-dashboard安装1234567891011121314151617181920212223# 下载镜像docker pull siriuszg/kubernetes-dashboard-amd64docker tag siriuszg/kubernetes-dashboard-amd64 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.0wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yamlvi kubernetes-dashboard.yaml修改：type:NodePort# 生成client-certificate-datagrep 'client-certificate-data' ~/.kube/config | head -n 1 | awk '&#123;print $2&#125;' | base64 -d &gt;&gt; kubecfg.crt# 生成client-key-datagrep 'client-key-data' ~/.kube/config | head -n 1 | awk '&#123;print $2&#125;' | base64 -d &gt;&gt; kubecfg.key# 生成p12openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name "kubernetes-client"https://192.168.x.xxx:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxykubectl describe secret admin-user --namespace=kube-system node1将Node加到集群中123456789#!/bin/bashimages=(kube-proxy-amd64:v1.10.3 kube-scheduler-amd64:v1.10.3 kube-controller-manager-amd64:v1.10.3 kube-apiserver-amd64:v1.10.3 etcd-amd64:3.1.12 pause-amd64:3.1 k8s-dns-sidecar-amd64:1.14.8 k8s-dns-kube-dns-amd64:1.14.8 k8s-dns-dnsmasq-nanny-amd64:1.14.8)for imageName in $&#123;images[@]&#125; ; do docker pull anjia0532/$imageName docker tag anjia0532/$imageName k8s.gcr.io/$imageName docker rmi anjia0532/$imageNamedonekubeadm join 172.xx.xxx.xxx:6443 --token xxxxx --discovery-token-ca-cert-hash sha256:xxxxxxxxx k8s默认配置文件路径1/etc/kubernetes/manifests cni默认路径1/etc/cni/net.d 卸载集群想要撤销kubeadm做的事，首先要排除节点，并确保在关闭节点之前要清空节点。 在主节点上运行：12kubectl drain &lt;node name&gt; --delete-local-data --force --ignore-daemonsetskubectl delete node &lt;node name&gt; --grace-period=0 --force 然后在需要移除的节点上，重置kubeadm的安装状态：1kubeadm reset 如果你想重新配置集群，只需运行kubeadm init或者kubeadm join并使用所需的参数即可。 卸载cni123456789101112kubeadm resetsystemctl stop kubeletsystemctl stop dockerrm -rf /var/lib/cni/rm -rf /var/lib/kubelet/*rm -rf /etc/cni/ifconfig cni0 downifconfig flannel.1 downifconfig docker0 downip link delete cni0ip link delete flannel.1systemctl start docker Troubleshooting1journalctl -u kubelet]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[go-Golang NF]]></title>
    <url>%2F2018%2F09%2F30%2Fgo%2FNiox%20Golang%20NF%2F</url>
    <content type="text"><![CDATA[Golang NFNF简介NF是一个开发Go应用的框架。 Golang开发环境搭建windows下安装Golangwindows下的安装步骤如下：以go 1.6为例：下载go1.6.windows-amd64.zip,​官方下载地址，​墙内下载将下载的zip文件解压缩到期望安装的目录,这里假设该目录为%INSTALL_HOME%，解压缩完成后为 %INSTALL_HOME%/go配置环境变量GOROOT=%INSTALL_HOME%/goGOPATH=%GO_WORKING_DIR%将%GOROOT%/bin追加到系统的PATH环境变量下以上配置成功后，在命令行下分别运行go version和go env可以看到具体go版本信息和配置的环境变量信息 安装git-for-windowsgo get命令会使用到git,需要确保开发机器上的git命令可用。 可以下载安装​git-for-windows。 Eclipse IDE + GoclipseEclipse 4.5 (Mars) or later.Java VM version 8 or later. （Goclipse要求Java8)​Goclipse ​安装指南GDB安装及Goclipse配置 Goclipse的调试功能需要使用GDB，在Windows下需要安装[mingw-w64 ​http://mingw-w64.org/doku.php]在Eclipse的Preferences下的’C/C++’/‘Debug’/‘GDB’的配置页的gdb debugger中配置gdb可执行文件的具体路径。在Eclipse的Preferences下的’Go’/‘Tool’的配置页中配置和安装gocode和godef Glide包管理工具Glide 工具简介​Glide是golang包管理工具,相当于node的npm, python的pip, .net的NuGet等工具,用于管理golang开发中引用的第三方库.Glide提供简单易用的依赖库管理,简单配置glide.yaml文件后就可以获取github等地host的依赖库.除此之外还支持从本地git库中获取依赖库.方便开发者管理组织代码以及vendor依赖.主要特性 简单易用的vendor库管理 支持​versioning package 支持添加库别名, aliasing package 支持golang提供的工具 支持仓库缓存,$GOPATH中仓库的重用 一定程度上能避免重复引用引用依赖Glide 安装下载release的可执行文件Glide提供可执行文件的直接下载,根据target的运行环境自行选择binary下载, ​点此下载经过测试稳定易用的版本目前为0.8.3, 下载后添加到环境变量PATH中,确保glide命令可以在命令行执行从源码编译安装glide也是用golang开发的，因此使用go get可以从源码编译安装glide的最新版本。编译的可执行文件被install到gopath下。 1go get -u github.com/Masterminds/glide Glide 使用在使用glide命令工具前必须先正确设置GOPATH目录结构: 123456789101112131415161718- $GOPATH/src/myProject (Your project)||-- glide.yaml||-- glide.lock||-- main.go (Your main go code can live here)||-- mySubpackage (You can create your own subpackages, too)| || |-- foo.go||-- vendor |-- github.com | |-- Masterminds | |-- ... etc. Glide适用场景下的目录结构如上所示, glide.yaml文件中配置有依赖库的列表, 在命令行中glide.yaml同级目录中执行 glide install 命令, glide会创建vendor目录,并且将所有获取的依赖包放到vendor目录中.引用第三方包时, 和引用go get 取得的依赖时一样.例如: 1234glide get github.com/Masterminds/cookoogo get github.com/Masterminds/cookoo // "gopkg.in/mgo.v2/bson"import "github.com/Masterminds/cookoo" 以上两个命令依赖库的下载位置不同,但是引用时无区别 PS: Go1.5试用glide需要额外设置环境变量 GO15VENDOREXPERIMENT = 1, Go1.6则不需要设置 Glide Getglide get [package name] 能够获取参数中的扩展依赖,放在vendor目录下,并且生成glide.yaml中的对应条目 Glide Updateglide update (aliased to up) 能够获取并更新glide.yaml中所有条目,并且放在vendor目录下,对于每个item的依赖会进行递归扫描.对于依赖中的其他包管理配置文件Godep, GPM, gb等,glide也会识别并下载更新到vendor目录下. glide.lock 文件中会生成或被更新,包含每个当前的依赖包的版本信息,精确到特定的commit Glide Installglide install 能够获取并更新glide.lock file中的所有条目,由于glide.lock中包含版本信息,能够获取特定版本的依赖包. glide up 命令会重新生成或更新glide.lock文件. Glide novendorglide novendor (aliased to nv) Glide能够很好的和go工具一起使用,例如go test sample: 12go test ./... // 执行所有当前目录以及子目录下包括vendor目录下的test代码go test $(glide novendor) //执行所有当前目录以及子目录下,不包括vendor目录下的test代码 Glide Rebuildglide rebuild 重新编译第三方依赖,在gopath下的pkg目录下生成.a文件.例子: 12345$ glide rebuild[INFO] Building dependencies.[INFO] Running go build github.com/kylelemons/go-gypsy/yaml[INFO] Running go build github.com/Masterminds/cookoo/cli[INFO] Running go build github.com/Masterminds/cookoo glide.yaml例子: 1234567package: github.com/Masterminds/glideimport: - package: github.com/Masterminds/semver // 从github.com - package: github.com/Masterminds/cookoo // 别名 vcs: git version: ^1.2.0 repo: git@192.168.1.101/cookoo.git // 从远程git仓库下载, 也可以是本地仓库 Config Center(nconf)nconf简介nconf是NF框架基于​etcd的实现的集中配置管理中心(类似于淘宝的diamond和百度的disconf)nconf可以为各种业务组件提供统一的配置管理服务。nconf当前具有如下特点：支持配置的分布式管理和配置发布统一化提供简单的web管理端支持多目录,多配置值监听配置值的加密解密功能nconf.NConfniox/nf/nconf包提供了一个NConf接口，提供访问Config Center的基本功能.该接口定义如下： 123456789101112131415type NConf interface &#123; Get(key string) string Set(key string, value string) Delete(key string, recursive bool) Watch(key string, processor func(NodeMap)) GetInt(key string) int GetNodeMap(key string) NodeMap GetNodes(key string) NNode&#125; 使用nconf包下的func NewNConf(machines []string, userName, password string) NConf函数可以获取一个NConf接口的实例，全局持有即可，通过上面定义的方法从Config Center获取配置数据。nconf使用示例基于nconf读取配置信息，创建redis基础设施，监控redis配置，发生变化时重新初始化基础资源. 1234567891011121314151617181920212223var ( redis nredis.Redis)func init() &#123; mutex.Lock() defer mutex.Unlock() cfgKey := "/res/redis" // 从nconf中获取redis相关配置 cfg := ncf.GetNodeMap(cfgKey) // 创建redis基础设施 createRedis(cfg) // 监控redis相关配置,配置变化时重建基础设施 ncf.Watch(cfgKey, createRedis)&#125;func createRedis(cfg nconf.NodeMap) &#123; address := cfg.GetString("/res/redis/address") password := cfg.GetString("/res/redis/password") dbIndex := cfg.GetInt("/res/redis/dbIndex") redis = nredis.NewRedis(address, password, dbIndex)&#125; nconf web管理端使用nconf管理后台可以维护配置中心存放的配置信息。开发环境nconf​管理端地址No image “NConfMangementConsole.png” attached to PcOneNf基础设施和资源NF框架提供mysql 使用NF框架提供的特性之前,需要在项目目录中建立infra目录添加初始化代码, 根据需要初始化需要用到的模块,并且要添加导入nconf.ini配置文件到你的项目中,以便NF框架连接到etcd集群使用之前请首先取得glide.yaml, glide.lock文件执行glide install命令以获取第三方依赖 目录结构: 12345678910111213141516171819202122232425- $GOPATH/src/myProject (Your project)||-- glide.yaml // "gopkg.in/mgo.v2/bson"||-- glide.lock||-- main.go (Your main go code can live here)||-- nconf.ini // 包含etcd配置信息||-- infra| || |-- res| || |-- init.go| |-- nconf.go //nconf 配置初始化(mandatory) | |-- mysql.go | |-- 其他模块 ||-- vendor |-- github.com | |-- Masterminds | |-- ... etc. nsqlnsql 示例示例数据库mysql 12345type Hospital struct &#123; Id int `db:"ID"` Name string `db:"NAME"` CityCode string `db:"CITY_CODE"`&#125; Get查询单个123456789101112query := "SELECT ID , NAME , CITY_CODE FROM master_hospital WHERE ID = ?"result := &amp;Hospital&#123;&#125;if !db.Get(result, query, 9) &#123; result = nil&#125;fmt.Println(result)query := "SELECT NAME FROM master_hospital WHERE ID = ?"result := ""if !db.Get(&amp;result, query, 9) &#123; fmt.Println("未获取到")&#125;fmt.Println(result) NamedGet查询单个1234567891011121314query := "SELECT ID , NAME , CITY_CODE FROM master_hospital WHERE ID = :ID"result := &amp;Hospital&#123;&#125;arg := &amp;Hospital&#123;Id: 9&#125;if !db.NamedGet(result, query, arg) &#123; result = nil&#125;fmt.Println(result)query := "SELECT NAME FROM master_hospital WHERE ID = :ID"result := ""arg := &amp;Hospital&#123;Id: 19&#125;if !db.NamedGet(&amp;result, query, arg) &#123; fmt.Println("未获取到")&#125;fmt.Println(result) Select查询多个12345678query := &quot;SELECT ID , NAME , CITY_CODE FROM master_hospital WHERE ID &gt; ? AND ID &lt; ?&quot;result := []*Hospital&#123;&#125;db.Select(&amp;result, query, 2, 10)fmt.Println(result)query := &quot;SELECT ID FROM master_hospital WHERE ID &gt; ? AND ID &lt; ?&quot;result := []int&#123;&#125;db.Select(&amp;result, query, 2, 10)fmt.Println(result) NamedSelect查询多个12345678910query := "SELECT ID , NAME , CITY_CODE FROM master_hospital WHERE ID &lt; :ID"result := []*Hospital&#123;&#125;arg := &amp;Hospital&#123;Id: 10&#125;db.NamedSelect(&amp;result, query, arg)fmt.Println(result)query := "SELECT ID FROM master_hospital WHERE ID &lt; :ID"result := []int&#123;&#125;arg := &amp;Hospital&#123;Id: 10&#125;db.NamedSelect(&amp;result, query, arg)fmt.Println(result) Exec和NamedExec1234567query := "UPDATE master_hospital SET NAME= ? WHERE ID = ?"result := db.Exec(query, "虚拟医院", 9)fmt.Println(result.RowsAffected())query := "UPDATE master_hospital SET NAME= :NAME WHERE ID = :ID"hosp := &amp;Hospital&#123;Id: 9, Name: "虚拟医院"&#125;result := db.NamedExec(query, hosp)fmt.Println(result.RowsAffected()) Begin和Tx123456tx := db.Begin()query := "UPDATE master_hospital SET NAME= :NAME WHERE ID = :ID"hosp := &amp;Hospital&#123;Id: 9, Name: "虚拟医院1"&#125;result := tx.NamedExec(query, hosp)fmt.Println(result.RowsAffected())tx.Commit() Prepare和PrepareNamed123456789query := "UPDATE master_hospital SET NAME= :NAME WHERE ID = :ID"stmt := db.PrepareNamed(query)hosp1 := &amp;Hospital&#123;Id: 9, Name: "虚拟医院 v2.0+"&#125;hosp2 := &amp;Hospital&#123;Id: 3, Name: "安徽省省直机关医院"&#125;result1 := stmt.NamedExec(hosp1)result2 := stmt.NamedExec(hosp2)fmt.Println(result1.RowsAffected(), result2.RowsAffected()) 数据访问访问对象示例目录结构: 1234567891011121314151617181920212223242526272829303132- $GOPATH/src/myProject (Your project)||-- glide.yaml||-- glide.lock||-- main.go (Your main go code can live here)||-- nconf.ini // 包含etcd配置信息||-- infra| || |-- res| | || | |-- init.go| | |-- nconf.go //nconf 配置初始化(mandatory) | | |-- mysql.go | || |-- data //包含dao 文件| | || | |-- config_hospital_cloud_dao.go // | || |-- model //包含数据实体| || |-- config_hospital_cloud.go // ||-- vendor |-- github.com | |-- Masterminds | |-- ... etc. 目录结构如上所示 初始化NF框架中mysql模块nsqlinfra/res/mysql.go: 1234567891011121314151617181920212223242526272829303132333435package resimport ( _ "github.com/go-sql-driver/mysql" "niox/nf/nconf" "niox/nf/nsql")var ( db nsql.DB)func initDB() &#123; mutex.Lock() defer mutex.Unlock() cfgKey := "/res/mysql" // 指定etcd中对应的key cfg = ncf.GetNodeMap("/res/mysql") // 从etcd中取出mysql连接字符串 createDB(cfg) // 建立DB连接池 ncf.Watch(cfgKey, createDB) // 监听指定etcd key下的变化,如果存在变化,自动使用新配置重新初始化db连接池&#125;func createDB(cfg nconf.NodeMap) &#123; // [username[:password]@][protocol[(address)]]/dbname[?param1=value1&amp;...&amp;paramN=valueN] dsn := cfg.GetString("/res/mysql/dsn") db = nsql.NewDB("mysql", dsn)&#125;func GetDB() nsql.DB &#123; return db&#125;func Close() &#123; db.Close()&#125; infra/res/init.go: 12345678910111213package resimport ()var Logger seelog.LoggerInterfacefunc init() &#123; //首先初始化nconf initNConf() initDB() // 调用同为res包下的mysql.go的initDB方法,初始化mysql模块&#125; 定义Dao以及model实体infra/data/config_hospital_cloud_dao.go: 123456789101112131415161718192021222324252627282930313233343536373839404142434445package dataimport ( "niox/infra/model" "niox/infra/res" "niox/nf/nsql")type ConfigHospitalCloudDao interface &#123; // 根据医院id获取 医院PC2配置信息 GetByHospId(hospId int) *model.ConfigHospitalCloud&#125;func NewConfigHospitalCloudDao() ConfigHospitalCloudDao &#123; return &amp;configHospitalCloudDaoImpl&#123;DB: res.GetDB()&#125;&#125;type configHospitalCloudDaoImpl struct &#123; nsql.DB&#125;// 根据医院id获取 医院PC2配置信息func (dao *configHospitalCloudDaoImpl) GetByHospId(hospId int) *model.ConfigHospitalCloud &#123; sql := `SELECT chc.ID, chc.HOSPITAL_ID, chc.VERSION_ID, chc.IP, chc.PORT, chc.TIMEOUT, chc.PROTOCOL, chc.DEFAULT_PROTOCOL, chc.OUTING_IP, chc.TRANSPORT_TYPE, chc.API_KEY, chc.ENABLE FROM config_hospital_cloud chc WHERE HOSPITAL_ID = ?` cfgHc := &amp;model.ConfigHospitalCloud&#123;&#125; if dao.DB.Get(cfgHc, sql, hospId) &#123; return cfgHc &#125; return nil&#125; infra/data/config_hospital_cloud_dao.go: 123456789101112131415161718192021package modelimport ( "niox/nf/util/lang")// 首先查看niox/nf/util/lang 包中封装的数据库类型定义, 理解lang.Int等类型为golang基础类型的可空封装type ConfigHospitalCloud struct &#123; Id lang.Int `db:"ID" json:"id"` HospitalId lang.Int `db:"HOSPITAL_ID" json:"hospitalId"` VersionId lang.Int `db:"VERSION_ID" json:"versionId"` Ip lang.String `db:"IP" json:"ip"` Port lang.Int `db:"PORT" json:"port"` Timeout lang.Int `db:"TIMEOUT" json:"timeout"` Protocol lang.String `db:"PROTOCOL" json:"protocol"` DefaultProtocol lang.Int `db:"DEFAULT_PROTOCOL" json:"defaultProtocol"` OutingIp lang.String `db:"OUTING_IP" json:"outingIp"` TransportType lang.Int `db:"TRANSPORT_TYPE" json:"transportType"` ApiKey lang.String `db:"API_KEY" json:"apiKey"` Enable lang.Int `db:"ENABLE" json:"enable"`&#125; 使用Dao以及model访问数据库main.go: 12345678910111213141516package mainimport ( "encoding/json" "fmt" "niox/infra/data" "niox/infra/model")func main() &#123; dao := data.NewConfigHospitalCloudDao() result := dao.GetByHospId(1) fmt.Println(result) bt, _ := json.Marshal(result) fmt.Println(string(bt))&#125; nmgonmgo 示例示例mongo实体12345type Person struct &#123; Name string Age int ID bson.ObjectId `bson:"_id,omitempty"`&#125; 示例Insert1res.GetMongo().Insert("CollectionName", Person&#123;ID: NewObjectId(), Name: "foo", Age: 10&#125;) 示例Update1res.GetMongo().Update("CollectionName", M&#123;"name": "foo"&#125;, M&#123;"$inc": M&#123;"age": 1&#125;&#125;) 示例UpdateAll1res.GetMongo().UpdateAll("CollectionName", M&#123;"name": "foo"&#125;, M&#123;"$inc": M&#123;"age": 1&#125;&#125;) 示例Upsert1res.GetMongo().Upsert("CollectionName", M&#123;"id": id&#125;, Person&#123;ID: id, Name: "foo", Age: 10&#125;) 示例Find1234res.GetMongo().Find("CollectionName", M&#123;"name": "foo"&#125;, func(query *Query) &#123; query.All(&amp;res) // query.Skip(10).Limit(10).All(&amp;res) // pipe &#125;) NMgo API:Mongo interfaceInsert(collection string, value …interface{}) 123456789101112collection 传入插入的集合, value 传入需要插入的数据结构,可以为多个Update(collection string, selector, value interface&#123;&#125;) collection 传入集合名字, selector 传入过滤selector, value 传入update结构 Update仅仅更新一条数据,如果需要更新所有符合条件的数据请用UpdateAllUpdateAll?(collection string, selector, value interface&#123;&#125;) *ChangeInfo? collection 传入集合名字, selector 传入过滤selector, value 传入update结构, 返回 ChangeInfo? 结构指针Upsert(collection string, selector, value interface&#123;&#125;) *ChangeInfo? collection 传入集合名字, selector 传入过滤selector, value 传入结构数据, 返回ChangeInfo 结构指针Find(collection string, selector M, fn func(query Query)) collection 传入集合名字, selector 传入过滤selector, 传入handler function, 在返回query中,使用query提供接口自定义parse数据Remove(collection string, selector M) collection 传入集合名字, selector 传入过滤selector 删除操作Query interface Batch(n int) Query123456789101112131415161718192021Batch Size 在mongo数据库中定义, 默认batch size (100 docs 4MB)Prefetch(p float64) Query Prefetch 如果iter中待处理的doc数量为 P * batch size, 则开始获取下一个batch的数据, 默认值为0.25. 例如 query.Batch(200).Prefetch(0.25) batch size 设置为200, prefetch 会在iter中剩余50个待处理的doc时,预先获取下一个batchSkip(n int) Query Skip 跳过前n条数据Limit(n int) Query Limit 获取n条数据Select(selector interface&#123;&#125;) Query selector 传入结构化过滤selectorSort(fields ...string) Query fields 传入field名字, 按传入fields排序, 如果需要反序,在field名字前加减号. .Sort(&quot;firstname&quot;, &quot;-lastname&quot;)One(result interface&#123;&#125;) bool result 传入结构指针, 从query中取出一个doc, 赋值到result中All(result interface&#123;&#125;) result 传入切片, 从query中取出所有doc, 赋值到resultCount() int 返回query中doc数量Distinct(key string, result interface&#123;&#125;) key 传入需要去重的key, result 传入切片, unmarshal当前query按照传入key去重后的结果到result切片里MapReduce?(job *MapReduce?, result interface&#123;&#125;) *MapReduceInfo? MapReduce? 在当前query上执行MapReduce 目录结构: 12345678910111213141516171819202122232425262728- $GOPATH/src/msyProject (Your project)||-- glide.yaml||-- glide.lock||-- main.go (Your main go code can live here)||-- nconf.ini // 包含etcd配置信息||-- infra| || |-- res| | || | |-- init.go| | |-- nconf.go //nconf 配置初始化(mandatory) | | |-- mongo.go | || |-- model //包含数据实体| || |-- ||-- vendor |-- github.com | |-- Masterminds | |-- ... etc. 目录结构如上所示 初始化NF框架中mongo模块infra/res/mongo.go: 12345678910111213141516171819202122232425262728293031package resimport ( "niox/nf/nconf" "niox/nf/nmgo")var ( mongo nmgo.Mongo)func initMongo() &#123; mutex.Lock() defer mutex.Unlock() cfgKey := "/res/mongo" cfg := ncf.GetNodeMap(cfgKey) createMongo(cfg) ncf.Watch(cfgKey, createMongo)&#125;func createMongo(cfg nconf.NodeMap) &#123; // mongo地址,例如mongodb://username:password@hostname:port/databasename url := cfg.GetString("/res/mongo/url") mongo = nmgo.NewMongo(url)&#125;func GetMongo() nmgo.Mongo &#123; return mongo&#125; main.go: 123456789101112131415type Person struct &#123; Name string Age int ID bson.ObjectId `bson:"_id,omitempty"`&#125;... res.GetMongo().Insert(dummyCol, Person&#123;ID: NewObjectId(), Name: "foo", Age: 10&#125;) res.GetMongo().Update(dummyCol, M&#123;"name": "foo"&#125;, M&#123;"$inc": M&#123;"age": 1&#125;&#125;) res.GetMongo().UpdateAll(dummyCol, M&#123;"name": "foo"&#125;, M&#123;"$inc": M&#123;"age": 1&#125;&#125;) res.GetMongo().Upsert(dummyCol, M&#123;"id": id&#125;, Person&#123;ID: id, Name: "foo", Age: 10&#125;) res.GetMongo().Find(dummyCol, M&#123;"name": "foo"&#125;, func(query *Query) &#123; query.All(&amp;res) &#125;)... nredisniox/nf/nredis包提供了一个Redis接口，提供了访问redis数据库的基本功能. nredis.Redis一个Redis接口的实例对应一个redis库。 在程序中使用nredis包的NewRedis(redisServer, redisPassword string, dbIndex int) Redis函数获取一个Redis接口的实例,在资源层全局持有即可。 Redis接口如下： 12345678910111213141516171819type Redis interface &#123; GetString(key string) (string, bool) SetString(key, value string, ttl ...int64) GetObject(key string, value interface&#123;&#125;) bool SetObject(key string, value interface&#123;&#125;, ttl ...int64) GetStringMap(key string) map[string]string SetStringMap(key string, fields map[string]string) Delete(key string) Deletes(keys ...string) GetConn() Conn&#125; Redis的接口的GetXXX,SetXXX,Delete方法的使用方式十分明显，这里不再展开. nredis.Conn使用Redis接口的GetConn方法GetConn() Conn可以取得一个连接.注意使用Conn，需要使用defer调用Conn的Close方法 Conn接口中的方法不是并发调用安全的。 使用Conn的Do方法Do(cmd string, args …interface{}) *reply,可以直接执行​redis命令用来实现更加复杂的功能。例如: 事务 Redis的事务提供了一种“将多个命令打包， 然后一次性、按顺序地执行”的机制， 并且事务在执行的期间不会主动中断 —— 服务器在执行完事务中的所有命令之后， 才会继续处理其他客户端的其他命令。 一个事务从开始到结束经过以下三个阶段： 开始事务命令入队执行事务12345678910redis := res.GetRedis()conn := redis.GetConn()defer conn.Close()conn.Do("MULTI")conn.Do("INCR", "foo")conn.Do("INCR", "bar")result, err := conn.Do("EXEC").Ints()if err != nil &#123; ... &#125; 发布订阅pub/subsub:123456789101112131415161718192021redis := res.GetRedis()conn := redis.GetConn()defer conn.Close()conn.Send("SUBSCRIBE", "/chat")conn.Flush()for &#123; reply := conn.Receive() var kind string var ch string reply = reply.Scan(&amp;kind, &amp;ch) switch kind &#123; case "subscribe": fmt.Println("订阅:", ch) case "message": var msg string reply = reply.Scan(&amp;msg) fmt.Println("收到消息:", msg, reply.Error()) default: fmt.Println(kind) &#125;&#125; pub:12345redis := res.GetRedis()conn := redis.GetConn()defer conn.Close()count, err := conn.Do("PUBLISH", "/chat", "hello world").Int()fmt.Println(count, err) nesNES API: ES interface123456789101112Search(esindex string, estype string, esargs map[string]interface&#123;&#125;, esquery interface&#123;&#125;) SearchResult? esindex 传入index名字, estype 传入type, esargs 传入参数, esquery 传入esqueryIndex(esindex string, estype string, esidcolumn string, esargs map[string]interface&#123;&#125;, esdata interface&#123;&#125;) BaseResponse? esindex 传入index名字, estype 传入type, esidcolumn 使用数据中某一列当做ID, 传入列名, esargs 传入参数, esdata 传入结构化数据IndexWithID(esindex string, estype string, esid string, esargs map[string]interface&#123;&#125;, esdata interface&#123;&#125;) BaseResponse? esindex 传入index名字, estype 传入type, esid 传入id, esargs 传入参数, esdata 传入结构化数据Update(esindex string, estype string, esid string, esargs map[string]interface&#123;&#125;, esdata interface&#123;&#125;) BaseResponse? esindex 传入index名字, estype 传入type, esid 传入id, esargs 传入参数, esdata 传入结构化数据Delete(esindex string, estype string, esid string, esargs map[string]interface&#123;&#125;) BaseResponse? esindex 传入index名字, estype 传入type, esid 传入id, esargs 传入参数BulkIndex?(esindex string, estype string, esidcolumn string, parent string, ttl string, esdata interface&#123;&#125;) bool esindex 传入index名字, estype 传入type, esidcolumn 使用数据中某一列当做ID, 传入列名, esargs 传入参数, esdata 传入结构化数据切片 使用示例 目录结构: 12345678910111213141516171819202122232425262728- $GOPATH/src/msyProject (Your project)||-- glide.yaml||-- glide.lock||-- main.go (Your main go code can live here)||-- nconf.ini // 包含etcd配置信息||-- infra| || |-- res| | || | |-- init.go| | |-- nconf.go //nconf 配置初始化(mandatory) | | |-- es.go | || |-- model //包含数据实体| || |-- ||-- vendor |-- github.com | |-- Masterminds | |-- ... etc. 初始化NF框架中ES模块 infra/res/es.go: 12345678910111213141516171819202122232425262728package resimport ( "niox/nf/nconf" "niox/nf/nes")var ( es nes.ES)func initES() &#123; mutex.Lock() defer mutex.Unlock() cfgKey := "/res/es" cfg := ncf.GetNodeMap(cfgKey) createES(cfg) ncf.Watch(cfgKey, createES)&#125;func createES(cfg nconf.NodeMap) &#123; es = nes.NewES(cfg.GetString("/res/es/address"), cfg.GetString("/res/es/username"), cfg.GetString("/res/es/password"))&#125;func GetES() nes.ES &#123; return es&#125; main.go: 12345678910111213141516171819202122 query :=`&#123; "query" : &#123; "term" : &#123; "id" : 9 &#125; &#125;&#125;` // hospconfig 为带有json标签的结构体定义 result := hospConfig&#123;&#125; resp := res,.Search("gd", "hosp", nil, query) json.Unmarshal(*resp.Hits[0].Source, &amp;result) // 添加新doc到index gd, type haha, 并且用Name 列当做ID m := MyUser&#123;Name:"alex", Age: 10&#125; resp := es.Index("gd", "haha", "Name", nil, m) // 以切片的方式添加新docs data := []MyUser&#123;MyUser&#123;Name:"alex1", Age: 1&#125;, MyUser&#123;Name:"alex2", Age:2&#125;&#125; ok := es.BulkIndex("gd", "haha", "Name", "", "", data) // 删除index下的type es.Delete("gd", "haha", "", nil) Niox Api2 Goniox/service/api2包是Niox PC2 Api2 Client在Golang下的实现. idlniox/service/api2/idl下放置api2的idl文件,在windows执行该目录下的gen.bat基于idl生成生成go代码. 生成代码的目录结构如下,其结构和api2 idl定义的结构一致。 1234567891011niox/service/api2/tf -- basedata -- xx.go -- enums -- xx.go -- request -- xx.go -- response -- xx.go -- service -- xx.go api2 interface and proxy生成的go代码中，在niox/service/api2/service包下包含api2各个service接口。如：SelfCheckService?, MasterDataService等等. 为便于使用，重新在niox/service/api2中定义这些接口，并以proxy的方式实现，结合PC1中存放的各个医院的PC2配置信息，实现按不同医院id获取具体的api2 service。 api2包提供了baseService接口和baseServiceProxy结构，基于这两个类型可以方便的完成api2各个service接口的定义和proxy实现。 以SelfCheckService为例： 在api2包下创建selfcheckservice_proxy.go文件.在其中编译selfCheckService接口，内部组合(嵌套)baseService接口，同时重定义HeartBeat方法。 1234type selfCheckService interface &#123; baseService HeartBeat(heartBeatRequest *request.HeartBeatRequest) *basedata.Result_&#125; 编写selfCheckServiceProxy结构，内部组合baseServiceProxy结构和基于idl生成的service.SelfCheckService结构。 1234type selfCheckServiceProxy struct &#123; baseServiceProxy service.SelfCheckService&#125; 为selfCheckServiceProxy添加HeartBeat方法使其实现selfCheckService 接口 12345678910111213func (srv *selfCheckServiceProxy) HeartBeat(heartBeatRequest *request.HeartBeatRequest) *basedata.Result_ &#123; defer srv.ifAutoClose() //设置认证信息 heartBeatRequest.Security = srv.createSecurity() //记录请求日志 srv.logRequest(heartBeatRequest.Security, heartBeatRequest) //调用api2 resp, err := srv.SelfCheckService.HeartBeat(heartBeatRequest) //记录响应日志 srv.logResponse(heartBeatRequest.Security, resp, err) panicErr(err) return resp&#125; 在api2.go中编写根据医院id创建selfCheckService 接口实例的两个New函数 123456789func NewSelfCheckService(hospId int) selfCheckService &#123; return NewSelfCheckServiceAutoClose(hospId, true)&#125;func NewSelfCheckServiceAutoClose(hospId int, autoClose bool) selfCheckService &#123; baseProxy := createBaseServiceProxy("SelfCheckService", hospId, autoClose) srv := service.NewSelfCheckServiceClientProtocol(baseProxy.transport, baseProxy.protocol, baseProxy.protocol) return &amp;selfCheckServiceProxy&#123;baseServiceProxy: baseProxy, SelfCheckService: srv&#125;&#125; 使用方式，在业务组件中使用api2.NewSelfCheckService(hospId)获取selfCheckService实例，调用对应的方法即可。 另外api2包还暴露了api2.GetHospConfig(hospId int)用来返回指定医院PC2的配置信息. SeelogSeelog是适用于golang的logging框架,提供灵活易学的日志分发,过滤,组织格式化等功能. Seelog用golang实现 特性 XML可配置修改配置文件后,可支持不用重启APP立即生效配置支持多项目, 多方法使用不同配置文件灵活可配置的message格式支持同时输出到多个stream支持console, file, buffered, rolling, smtp 等等writer…使用示例 12345678package mainimport log "github.com/cihub/seelog"func main() &#123; defer log.Flush() log.Info("Hello from Seelog!")&#125; XML配置文件示例 12345678910111213&lt;seelog&gt; &lt;outputs formatid="common"&gt; &lt;filter levels="critical"&gt; &lt;rollingfile type="date" filename="logs/goapp-critical.log" datepattern="02.01.2006"/&gt; &lt;/filter&gt; &lt;filter levels="info"&gt; &lt;rollingfile type="date" filename="logs/goapp-info.log" datepattern="02.01.2006"/&gt; &lt;/filter&gt; &lt;/outputs&gt; &lt;formats&gt; &lt;format id="common" format="%Date/%Time [%LEV] %FullPath %Func %Line %Msg%n" /&gt; &lt;/formats&gt;&lt;/seelog&gt; %Msg 为消息主体 根据日期rolling分文件日志 根据级别过滤日志内容 应用构建直接编译成指定平台上的可执行文件. 交叉编译命令行进入golang代码的main包所在目录, 修改环境变量 12GOARCH = "amd64"GOOS = "linux" 执行go install 命令即可生成可执行文件. 使用glide plugin机制构建windows下编写批处理文件glide-bt.bat示例如下.直接执行此文件或使用glide bt命令进行构建。 12345678910111213141516171819@echo offcd /d %~dp0/cd /d ../..echo SET GOPATH=%cd%SET GOPATH=%cd%cd /d %~dp0/echo SET GOOS=linuxSET GOOS=linuxecho SET GOARCH=amd64SET GOARCH=amd64cd /d %~dp0/app/api1echo build api1call go install ProfilingWeb应用的profiling引用net/http/profile包即可添加路由到/debug/pprof/… 路径下访问示例​http://localhost:XXXX/debug/pprof/ 代码示例: 123456789101112131415// 使用原生golang http包添加以下引用即可_ "net/http/pprof"// 使用martini框架,需要手动注册以下路由m.Group("/debug/pprof", func(r martini.Router) &#123; r.Any("/", pprof.Index) r.Any("/cmdline", pprof.Cmdline) r.Any("/profile", pprof.Profile) r.Any("/symbol", pprof.Symbol) r.Any("/block", pprof.Handler("block").ServeHTTP) r.Any("/heap", pprof.Handler("heap").ServeHTTP) r.Any("/goroutine", pprof.Handler("goroutine").ServeHTTP) r.Any("/threadcreate", pprof.Handler("threadcreate").ServeHTTP)&#125;) 非Web应用的profiling可以引用runtime/pprof 包来监控信息,也可以引用net/http/pprof包,在goroutine中分配端口启动web服务即可]]></content>
      <categories>
        <category>go</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kubectl常用命令]]></title>
    <url>%2F2018%2F06%2F22%2Fk8s%2Fkubectl%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[kubectl常用命令创建pods：1kubectl create -f kubernetes-dashboard.yaml 查看pods：12kubectl get pods -n kube-systemkubectl get po -o wide -n kube-system 删除pods：1kubectl delete pods kubernetes-dashboard-302935354-0h7p6 -n kube-system 查看报错日志：1kubectl describe pods kubernetes-dashboard-2496492025-rwczb -n kube-system 查看明细日志：1kubectl logs kubernetes-dashboard-1338994370-w8bmt -n kube-system 动态修改服务1kubectl -n kube-system edit service kubernetes-dashboard 关键字补全1source &lt;(kubectl completion bash) 获取yaml模板123kubectl run --image=nginx my-deploy -o yaml --dry-run &gt; my-deploy.yamlkubectl get statefulset/foo -o yaml --export &gt; new.yamlkubectl get node/xx -o yaml --export &gt; node.yaml 创建secret，从私用仓库拉取镜像1kubectl create secret docker-registry myregistrykey --docker-server=https://index.docker.io/v1/ --docker-username=xxxx --docker-password=xxxx --docker-email=xxxx@qq.com 开放NodePort1kubectl expose deployment kube-node --type=NodePort helm命令12helm install --name elho-hook-1 ./elho-hookhelm del elho-hook-1 —purge QAQ:GPG error: http://archive.ubuntukylin.com:10006 xenial InRelease: The following signatures couldn’t be verified because the public key is not available: NO_PUBKEY 8D5A09DC9B929006A: 1apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 8D5A09DC9B929006 Q: kubectl get pod -n kube_get_comp_words_by_ref: command not foundA: 12source /etc/bash_completionsource &lt;(kubectl completion bash)]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Haproxy-配置]]></title>
    <url>%2F2018%2F06%2F11%2Flb%2FHaproxy%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[Haproxy配置文件说明12/usr/local/sbin/haproxy -f /etc/haproxy/haproxy.cfg -st `cat /var/run/haproxy.pid```` ####################全局配置信息######################## #######参数是进程级的，通常和操作系统（OS）相关######### global maxconn 20480 #默认最大连接数 log 127.0.0.1 local3 #[err warning info debug] chroot /var/haproxy #chroot运行的路径 uid 99 #所属运行的用户uid gid 99 #所属运行的用户组 daemon #以后台形式运行haproxy nbproc 1 #进程数量(可以设置多个进程提高性能) pidfile /var/run/haproxy.pid #haproxy的pid存放路径,启动进程的用户必须有权限访问此文件 ulimit-n 65535 #ulimit的数量限制 12345678910111213141516171819202122232425262728293031323334353637383940414243```#####################默认的全局设置###################### ##这些参数可以被利用配置到frontend，backend，listen组件## defaults log global mode http #所处理的类别 (#7层 http;4层tcp ) maxconn 20480 #最大连接数 option httplog #日志类别http日志格式 option httpclose #每次请求完毕后主动关闭http通道 option dontlognull #不记录健康检查的日志信息 option forwardfor #如果后端服务器需要获得客户端真实ip需要配置的参数，可以从Http Header中获得客户端ip option redispatch #serverId对应的服务器挂掉后,强制定向到其他健康的服务器 option abortonclose #当服务器负载很高的时候，自动结束掉当前队列处理比较久的连接 stats refresh 30 #统计页面刷新间隔 retries 3 #3次连接失败就认为服务不可用，也可以通过后面设置 balance roundrobin #默认的负载均衡的方式,轮询方式 #balance source #默认的负载均衡的方式,类似nginx的ip_hash #balance leastconn #默认的负载均衡的方式,最小连接 contimeout 5000 #连接超时 clitimeout 50000 #客户端超时 srvtimeout 50000 #服务器超时 timeout check 2000 #心跳检测超时 12345678910111213141516171819202122232425262728293031323334####################监控页面的设置####################### listen admin_status #Frontend和Backend的组合体,监控组的名称，按需自定义名称 bind 0.0.0.0:65532 #监听端口 mode http #http的7层模式 log 127.0.0.1 local3 err #错误日志记录 stats refresh 5s #每隔5秒自动刷新监控页面 stats uri /admin?stats #监控页面的url stats realm xuequn\ xuequn #监控页面的提示信息 stats auth admin:admin #监控页面的用户和密码admin,可以设置多个用户名 stats auth admin1:admin1 #监控页面的用户和密码admin1 stats hide-version #隐藏统计页面上的HAproxy版本信息 stats admin if TRUE #手工启用/禁用,后端服务器(haproxy-1.4.9以后版本) errorfile 403 /etc/haproxy/errorfiles/403.http errorfile 500 /etc/haproxy/errorfiles/500.http errorfile 502 /etc/haproxy/errorfiles/502.http errorfile 503 /etc/haproxy/errorfiles/503.http errorfile 504 /etc/haproxy/errorfiles/504.http 1234567891011121314#################HAProxy的日志记录内容设置################### capture request header Host len 40 capture request header Content-Length len 10 capture request header Referer len 200 capture response header Server len 40 capture response header Content-Length len 10 capture response header Cache-Control len 8 1234567891011121314151617181920212223242526 #######################网站监测listen配置##################### ###########此用法主要是监控haproxy后端服务器的监控状态############listen site_status bind 0.0.0.0:1081 #监听端口 mode http #http的7层模式 log 127.0.0.1 local3 err #[err warning info debug] monitor-uri /site_status #网站健康检测URL，用来检测HAProxy管理的网站是否可以用，正常返回200，不正常返回503 acl site_dead nbsrv(server_web) lt 2 #定义网站down时的策略当挂在负载均衡上的指定backend的中有效机器数小于1台时返回true acl site_dead nbsrv(server_blog) lt 2 acl site_dead nbsrv(server_bbs) lt 2 monitor fail if site_dead #当满足策略的时候返回503，网上文档说的是500，实际测试为503 monitor-net 192.168.16.2/32 #来自192.168.16.2的日志信息不会被记录和转发 monitor-net 192.168.16.3/32 123456789101112131415161718########frontend配置############ #####注意，frontend配置里面可以定义多个acl进行匹配操作######## frontend http_80_in bind 0.0.0.0:80 #监听端口，即haproxy提供web服务的端口，和lvs的vip端口类似 mode http #http的7层模式 log global #应用全局的日志配置 option httplog #启用http的log option httpclose #每次请求完毕后主动关闭http通道，HA-Proxy不支持keep-alive模式 option forwardfor #如果后端服务器需要获得客户端的真实IP需要配置次参数，将可以从Http Header中获得客户端IP 1234567891011121314########acl策略配置#############acl xuequn_web hdr_reg(host) -i ^(www.xuequn.cn|ww1.xuequn.cn)$ #如果请求的域名满足正则表达式中的2个域名返回true -i是忽略大小写 acl xuequn_blog hdr_dom(host) -i blog.xuequn.cn #如果请求的域名满足www.xuequn.cn返回true -i是忽略大小写 #acl xuequn hdr(host) -i xuequn.cn #如果请求的域名满足xuequn.cn返回true -i是忽略大小写 #acl file_req url_sub -i killall #在请求url中包含killall=，则此控制策略返回true,否则为false #acl dir_req url_dir -i allow #在请求url中存在allow作为部分地址路径，则此控制策略返回true,否则返回false #acl missing_cl hdr_cnt(Content-length) eq 0 #当请求的header中Content-length等于0时返回true 1234567891011121314########acl策略匹配相应############# #block if missing_cl #当请求中header中Content-length等于0阻止请求返回403 #block if !file_req || dir_req #block表示阻止请求，返回403错误，当前表示如果不满足策略file_req，或者满足策略dir_req，则阻止请求 use_backend server_web if xuequn_web #当满足xuequn_web的策略时使用server_web的backend use_backend server_blog if xuequn_blog #当满足xuequn_blog的策略时使用server_blog的backend #redirect prefix http://192.168.16.3 code 301 if xuequn #当访问xuequn.cn的时候，用http的301挑转到http://192.168.16.3 default_backend server_bbs #以上都不满足的时候使用默认server_bbs的backend 12345678910111213141516171819202122232425262728##########backend的设置############## #下面我将设置三组服务器 server_web，server_blog，server_bbs###########################backend server_web############################# backend server_web mode http #http的7层模式 balance roundrobin #负载均衡的方式，roundrobin平均方式 cookie SERVERID #允许插入serverid到cookie中，serverid后面可以定义 option httpchk GET /index.html #心跳检测的文件 server web1 192.168.16.2:80 cookie web1 check inter 1500 rise 3 fall 3 weight 1 #服务器定义，cookie 1表示serverid为web1，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用， #fall 3是3次失败认为服务器不可用，weight代表权重 server web2 192.168.16.3:80 cookie web2 check inter 1500 rise 3 fall 3 weight 2 #服务器定义，cookie 1表示serverid为web2，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用， #fall 3是3次失败认为服务器不可用，weight代表权重 1234567891011121314151617181920###################################backend server_blog############################################### backend server_blog mode http #http的7层模式 balance roundrobin #负载均衡的方式，roundrobin平均方式 cookie SERVERID #允许插入serverid到cookie中，serverid后面可以定义 option httpchk GET /index.html #心跳检测的文件 server blog1 192.168.16.2:80 cookie blog1 check inter 1500 rise 3 fall 3 weight 1 #服务器定义，cookie 1表示serverid为web1，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用，fall 3是3次失败认为服务器不可用，weight代表权重 server blog2 192.168.16.3:80 cookie blog2 check inter 1500 rise 3 fall 3 weight 2 #服务器定义，cookie 1表示serverid为web2，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用，fall 3是3次失败认为服务器不可用，weight代表权重 1234567891011121314151617181920###################################backend server_bbs############################################### backend server_bbs mode http #http的7层模式 balance roundrobin #负载均衡的方式，roundrobin平均方式 cookie SERVERID #允许插入serverid到cookie中，serverid后面可以定义 option httpchk GET /index.html #心跳检测的文件 server bbs1 192.168.16.2:80 cookie bbs1 check inter 1500 rise 3 fall 3 weight 1 #服务器定义，cookie 1表示serverid为web1，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用，fall 3是3次失败认为服务器不可用，weight代表权重 server bbs2 192.168.16.3:80 cookie bbs2 check inter 1500 rise 3 fall 3 weight 2 #服务器定义，cookie 1表示serverid为web2，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用，fall 3是3次失败认为服务器不可用，weight代表权重]]></content>
      <categories>
        <category>lb</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux-文件权限]]></title>
    <url>%2F2018%2F05%2F04%2Flinux%2F%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[文件权限123456789101112131415161718192021222324444 r--r--r--600 rw-------644 rw-r--r--666 rw-rw-rw-700 rwx------744 rwxr--r--755 rwxr-xr-x777 rwxrwxrwx* 1-3位数字代表文件所有者的权限，* 4-6位数字代表同组用户的权限，* 7-9数字代表其他用户的权限。* 读取的权限等于4，用r表示；* 写入的权限等于2，用w表示；* 执行的权限等于1，用x表示；* 0（没有权限）；* 4（读取权限）；* 5（4+1 | 读取+执行）；* 6（4+2 | 读取+写入）；* 7（4+2+1 | 读取+写入+执行）* 以755为例：* 1-3位7等于4+2+1，rwx，所有者具有读取、写入、执行权限；* 4-6位5等于4+1+0，r-x，同组用户具有读取、执行权限但没有写入权限；* 7-9位5，同上，也是r-x，其他用户具有读取、执行权限但没有写入权限。 将用户添加到组的指令增加一个新用户到附加用户组useradd -G admins,ftp,www,developers cnzhx 增加一个新用户到主要用户组useradd -g developers cnzhx 将一个已有用户增加到一个已有用户组中usermod -a -G apache cnzhx 如果要同时将 cnzhx 的主要用户组改为 apache，则直接使用 -g 选项： usermod -g apache cnzhx 如果要将一个用户从某个组中删除gpasswd -d user group参照文献 文件已被删除，但是引用该文件的进程仍然活动1lsof | grep deleted 1du -h --max-depth=1 / 12chown -R mkdir -p This account is currently not available12cat /etc/passwd | grep apache发现它的shell是“/sbin /nologin”，需要将起改成“/bin/bash”]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux-系统信息]]></title>
    <url>%2F2018%2F02%2F28%2Flinux%2FLinux%E6%9F%A5%E7%9C%8BCPU%EF%BC%8C%E5%86%85%E5%AD%98%EF%BC%8C%E7%A1%AC%E7%9B%98%2F</url>
    <content type="text"><![CDATA[Linux查看CPU，内存，硬盘查看CPU查看CPU核数12# cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniqcpu cores : 4 查看CPU个数12# cat /proc/cpuinfo | grep &quot;physical id&quot; | uniq | wc -l2 **uniq命令：删除重复行;wc –l命令：统计行数** 查看CPU型号12# cat /proc/cpuinfo | grep &apos;model name&apos; |uniqmodel name : Intel(R) Xeon(R) CPU E5630 @ 2.53GHz 总结：该服务器有2个4核CPU，型号Intel(R) Xeon(R) CPU E5630 @ 2.53GHz 查看内存查看内存总数12#cat /proc/meminfo | grep MemTotalMemTotal: 32941268 kB //内存32G 查看内存条数1# dmidecode |grep -A16 &quot;Memory Device$&quot; 总结：该服务器有两条2G内存 ，空余4个插槽 查看硬盘查看硬盘大小12# fdisk -l | grep DiskDisk /dev/cciss/c0d0: 146.7 GB, 146778685440 bytes 总结：硬盘大小146.7G，即厂商标称的160G 同步系统时间12yum install -y ntpdate ntpdate time.nuri.net 123456time.nist.govtime.nuri.net0.asia.pool.ntp.org1.asia.pool.ntp.org2.asia.pool.ntp.org3.asia.pool.ntp.org 1hwclock -w 12#date#hwclock 12345定时执行时间同步任务，所以我们利用crontab -e 来添加定时任务#* */1 * * * root ntpdate time.nuri.net;hwclock -w 即：每隔一个小时同步一下internet时间。 TCP状态查看：1netstat -n | grep 60.214.137.170 查看公网IP：1ip addr show eth0 | grep inet | awk &apos;&#123; print $2; &#125;&apos; | sed &apos;s/\/.*$//&apos; 查看系统：1lsb_release -a 1cat /proc/version 查看yum安装创建相关文件：12rpm -qa|grep redis rpm -ql redis 挂载硬盘12umount /dev/vdb1fuser -mv /home uname -aLinux（系统名） iZ23jnmf7iwZ（节点名称） 2.6.32-431.23.3.el6.x86_64（操作系统的发行版号） #1 SMP Thu Jul 31 17:20:51 UTC 2014（内核版本） x86_64（硬件平台） x86_64（机器硬件名） x86_64（系统处理器的体系结构） GNU/Linux（操作系统） 查看外网ip1curl members.3322.org/dyndns/getip]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux-证书生成]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F%E8%AF%81%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[证书通过keytool生成证书生成私钥1keytool -genkeypair -alias certificatekey -keyalg RSA -validity 1095 -keystore elho_keystore.jks keystore:xxxxxxCN=elho, OU=neusoft, O=niox, L=dalian, ST=liaoning, C=cn 导出公钥证书1keytool -export -alias certificatekey -keystore elho_keystore.jks -rfc -file elho_cert.cer -storetype BKS 公钥导入并生成truststore:1keytool -import -alias certificatekey -file elho_cert.cer -keystore elho_truststore.jks 验证1keytool -list -v -keystore elho_keystore.jks 安卓BKS证书 JKS转PKCS12 1keytool -importkeystore -srckeystore elho_keystore.jks -destkeystore elho_keystore.p12 -srcstoretype jks -deststoretype pkcs12 PKCS12转PEM(生成的pem中包含了私钥和证书) 1openssl pkcs12 -nodes -in elho_keystore.p12 -out elho_keystore.pem CER转成BKS 1keytool -importcert -v -trustcacerts -file truststore.cer -alias certificatekey -keystore truststore4android.bks -provider org.bouncycastle.jce.provider.BouncyCastleProvider -providerpath ./bcprov-jdk15on-1.47.jar -storetype BKS -storepass AntE2a%GH_4G 免费官方证书Encrypt]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[TODO-持续更新]]></title>
    <url>%2F2017%2F11%2F20%2Fother%2FTODO%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[TODO第三方链接工具书Spring各种源码项目下载使用locust做服务器压力测试spring 熔断器Spring RestTemplate详解spring web源码思路结合Spring注解标签发布RMI / HTTPInvoker / Hessian / Burlap服务spring设计思想shiro豆瓣模拟登录验证码处理调研pdf加密Java 诊断工具 值得一看的代码库 国人写的模板引擎，代码质量很高：subchen/jetbrick-template-2x 数据结构和算法类的，同时有测试代码：buptdavid/datastructure | kdn251/interviews Java写的高性能数据库：jankotek/mapdb Netty实现的高性能RPC，有写博文分析：tang-jie/NettyRPC Java编写的原子组件库，内功非常深厚：mindwind/craft-atom 前点评网的一位大牛黄艺华写的爬虫框架：code4craft/webmagic 针对Java8的一系列代码示例，纯干货无废话：winterbe/java8-tutorial Java设计模式的总结以及代码和文章：iluwatar/java-design-patterns 线上问题排查神器-Btrace 增量数据同步神器-canal mysql中间件：atlas,mycat 分库分表数据库中间件：Sharding-JDBC 调用链: hydra,zipkin,CAT,Hiro,skywalking,pinpoint 代码静态检测工具：PMD canal监控对接一下：prometheus+grafana 安全监测工具：burpsuit,AWVS,Nmap,Nessus,Openvas,Metasploit,kalijdkutil包：ArrayList,HashMap,LinkedHashMap,LinkedList,HashTable,HashSet。lang包：String,Object,StringBuffer,StringBuilder,Integer 《如何变得有思想》 jdk里的util包，把这些类。这些类弄明白了，你可以上升一个台阶。还有平时你工作中用到什么类，就看什么类就ok了。可叹的是，有些人写了五六年代码，连String这个类的源码都没看过，还老是对我说未来很迷茫，不知道怎么提升好，其实我想说，这样不迷茫才怪。juc 包里的aqs框架Okhttp：android开发最受欢迎的http客户端，支持http2，websocket等最新协议。总体采用责任链模式，架构简单且扩展性强，看完几个主要的拦截器相当于把http协议重新学习了一遍。jdk8下的ConcurrentHashMap：Doug Lea 大神的大作，实现上非常精巧，采用cas操作就实现了无锁HashMap，仅仅在Hash冲突插入的情况下锁住一个hash桶，并发度比jdk7版的高出不少。spring-mvc：MVC模式的最佳实践，玩设计模式的癫狂之作，扩展性极强最优雅的网络请求库，一个Java文件：kevinsawicki/http-request 网络设置指引： 诗中有画，画中有诗]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx-使用]]></title>
    <url>%2F2017%2F09%2F08%2Flb%2Fnginx%2F</url>
    <content type="text"><![CDATA[nginxmaster进程会接收来自外界发来的信号，再根据信号做不同的事情。所以我们要控制nginx，只需要通过kill向master进程发送信号就行了。比如kill -HUP pid，则是告诉nginx，从容地重启nginx 第三方参照nginx优雅启动关闭nginx 正则从一份配置清单详解Nginx服务器配置 nginx header中带下划线不转换1underscores_in_headers on; root与alias区别123456location ~ ^/weblogs/ &#123; root /data/weblogs/www.ttlsa.com; autoindex on; auth_basic &quot;Restricted&quot;; auth_basic_user_file passwd/weblogs;&#125; 如果一个请求的URI是/weblogs/httplogs/www.ttlsa.com-access.log时.web服务器将会返回服务器上的/data/weblogs/www.ttlsa.com/weblogs/httplogs/www.ttlsa.com-access.log的文件 root会根据完整的URI请求来映射，也就是/path/uri。 123456location ^~ /binapp/ &#123; limit_conn limit 4; limit_rate 200k; internal; alias /data/statics/bin/apps/;&#125; alias会把location后面配置的路径丢弃掉.如果一个请求的URI是/binapp/a.ttlsa.com/favicon时，web服务器将会返回服务器上的/data/statics/bin/apps/a.ttlsa.com/favicon.jg 使用alias时，目录名后面一定要加”/“。 alias可以指定任何名称。 alias在使用正则匹配时，必须捕捉要匹配的内容并在指定的内容处使用。 alias只能位于location块中。 logrotate切割nginx日志配置使用系统自带的logrorate来切个nginx日志，位于/usr/sbin/logrotate假设服务器上有两个网站的nginx配置分别如下: 去除其它配置信息，只保留了日志相关A网站12access_log /data/logs/a.com/access.log;error_log /data/logs/a.com/error.log; B网站12access_log /data/logs/b.com/access.log;error_log /data/logs/b.com/error.log; 在/etc/logrotate.d/下创建一个配置文件 nginx, 内容如下: 这里可以添加你想切个的目录，也可以直接使用正则表达式1234567891011121314151617/data/logs/a.com/*.log/data/logs/b.com/*.log&#123; daily rotate 30 missingok dateext compress delaycompress notifempty sharedscripts postrotate if [ -f /usr/local/nginx/nginx.pid ]; then kill -USR1 `cat /usr/local/nginx/nginx.pid` fi endscript&#125; 需要注意的是你们的nginx.pid位置，不一定是在/usr/local/nginx/nginx.pid配置说明 配置 说明daily 指定转储周期为每天weekly 指定转储周期为每周monthly 指定转储周期为每月rotate 转储次数，超过将会删除最老的那一个missingok 忽略错误，如“日志文件无法找到”的错误提示dateext 切换后的日志文件会附加上一个短横线和YYYYMMDD格式的日期compress 通过gzip 压缩转储旧的日志delaycompress 当前转储的日志文件到下一次转储时才压缩notifempty 如果日志文件为空，不执行切割sharedscripts 只为整个日志组运行一次的脚本prerotate/endscript 在转储以前需要执行的命令可以放入这个对，这两个关键字必须单独成行postrotate/endscript 在转储以后需要执行的命令可以放入这个对，这两个关键字必须单独成行 3 测试执行以下命令进行测试logrotate -vf /etc/logrotate.d/nginx1然后到相应的日志目录下查看 （/data/logs/a.com/, /data/logs/b.com/）应该会有类似以下的文件:access.logaccess.log-20170626error.logerror.log-20170626 4 添加定时任务每日0点执行脚本 在终端运行 crontab -e插入以下语句0 0 * /usr/sbin/logrotate -vf /etc/logrotate.d/nginx]]></content>
      <categories>
        <category>lb</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[小故事-父亲去已婚女儿的家中]]></title>
    <url>%2F2017%2F08%2F10%2Flive%2F%E7%88%B6%E4%BA%B2%E5%8E%BB%E5%B7%B2%E5%A9%9A%E5%A5%B3%E5%84%BF%E7%9A%84%E5%AE%B6%E4%B8%AD%EF%BC%8C%E8%A2%AB%E7%9C%BC%E5%89%8D%E7%9A%84%E6%99%AF%E8%B1%A1%E9%9C%87%E6%83%8A%E4%BA%86%E2%80%A6%E2%80%A6%2F</url>
    <content type="text"><![CDATA[父亲去已婚女儿的家中，被眼前的景象震惊了……当一个父亲，把女儿的手递到另一个男人的手里，他渴望和期待的是女儿能过上幸福的日子。然而，有一天，他到女儿家去看她，突然发现女儿过的生活，并不是自己想象的那样。 ▼女儿几乎从一瞬间，从一个文静优雅的姑娘，变成了一个身兼保姆、妈妈、员工、妻子、女儿的多重身份的女汉子。 ▼父亲觉得有些痛心，因为那个号称是孩子父亲的人，并没有帮到女儿，反而还要女儿像宠爱一个大孩子一样伺候他。 ▼看着女儿要一边打电话一边打开煤气灶做饭，还要打开电脑去看工作进度，更要收拾熊孩子落在地上的玩具，父亲心底说不出的心酸，他有些怀疑，自己是否帮她选错了。 ▼一边是女婿的气定神闲看电视喝咖啡玩电脑，一边是女儿忙得的焦头烂额，老爸心里真是五味杂陈。 ▼女儿的电话一直没来得及放下，还要操心熊孩子，给熊孩子脱下脏了的衣服。 ▼女儿又穿梭于洗衣房跟厨房之间，她根本闲不下来，可是那个孩子的爸爸呢？ ▼女儿的电脑开着，但是手里还抱着一堆盘子，准备开饭。这是女儿的日常，她已经习惯，可是父亲心底却满满是泪。他开始后悔，后悔自己这些年做过的榜样。 ▼他还是忍住眼泪离开，跟女儿道别的时候，无比柔情蜜意。 ▼当父亲离开，女儿终于发现父亲留下了一封信，打开之后，看的热泪盈眶。 ▼作为父亲，他觉得自己这么多年，愧对自己的妻子，因为，自己跟女儿的老公一样，视若无睹妻子的付出。而作为父亲，他又不愿意自己的女儿也重走自己妻子的老路，这么多年，活成女汉子。 ▼所以，他告诉女儿，这个家，是两个人的家，需要孩子的父亲一起付出，这才是完整的家。 ▼当然，他更多的是对自己做了一个坏榜样而感到内疚，是自己这么多年来对妻子的忽略和理所当然，他如今想做的就是，从点滴做起，在这个家里，体贴妻子，当一个让妻子心底温暖起来的好丈夫，也给女儿做一个好榜样。 是啊，这虽然是一条广告片，可是却赚了许多人的热泪，之所以感动，是因为，这个父亲他意识到了现代家庭里父亲已经不再是那个只需要赚钱养家就可以在沙发上一趟看电视的父亲，父亲这个角色，赋予了更多的意义： 因为如果你不好好当个父亲你的女儿可能将来就会成为你妻子那样的女汉子因为父亲的形象潜意识成为女儿选择丈夫的标准因为你现在的家就是你孩子以后的原生家庭你的样子就是你女儿将来老公的样子！ 女儿婚礼，爸爸说：“我的小棉袄被人穿走了。 这是一段爸爸对女儿真情的告白…… 你小时候，不敢抱你怕胡渣弄疼你 你长大了……只愿和妈妈交心，我只能在一边呵护你； 你成年了，我天天盼你电话，只为换一份舒心。 弹指间……你就要和身边这个小子走了，但我还没来得及说句爱你。 只希望他会比我还疼你。 但女儿，我只想你知道。我依然会用余下的人生去守护你。 我一直想要一个儿子而不是一个女儿，其实并不是因为我不喜欢你,而是因为过去的20多年我都不愿意去想象你离开我的这一天，这天我将失去我的一切，但这一天还是来了。 出嫁前，硬汉一样的爸爸哽噎的说，“以后就剩老两口了，一点也不热闹了”。第一次，看到爸爸流泪，到了自己才发现，父亲在女儿出嫁那天，是这样的心情。 父亲，面对女儿出嫁的那一刻，也许是这多年来最凌乱的一种感情了。 很多时候，我们总以为自己有的是机会，孰料其实人生是减法，见一面少一面。在有限的人生里，请一定记得对他好。 多少年后你还会记得在那个甜蜜，喜悦，幸福，各种情绪交织的早晨，爸爸充满着复杂的情绪为女儿的婚礼忙忙碌碌着，生怕对那一场婚礼细节考虑得有任何不周全。 小时候因为摔跤哭了，父亲会用宽大得手掌擦去女儿得眼泪。此刻，女儿又一次哭了，而父亲嘴角得微笑是他全部得语言。 你能看到照片中父亲得失落。父爱如此深沉，无言。 女儿出嫁时父亲对她说：女儿，你们之间的矛盾和不高兴的事不要给我讲，因为你终会原谅他，但我不会。 拥抱再紧，也总是要松开。这个世界上，只有一种爱是为了放手。 如果可以，请把我留在童年里，留在青春里，留在最美好得时光里。 因为哪里，有父亲最亲密无间得爱。]]></content>
      <categories>
        <category>live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[小故事-大树之恩]]></title>
    <url>%2F2017%2F08%2F10%2Flive%2F%E5%A4%A7%E6%A0%91%E4%B9%8B%E6%81%A9%2F</url>
    <content type="text"><![CDATA[大树之恩很久很久以前，有一棵又高又大的树。一位小男孩，天天到树下来，他爬上去摘果子吃，在树荫下睡觉。他爱大树，大树也爱和他一起玩耍。后来，小男孩长大了，不再天天来玩耍。一天他又来到树下，很伤心的样子。大树要和他一起玩，男孩说：“不行，我不小了，不能再和你玩，我要玩具，可是没钱买。”大树说：“很遗憾，我也没钱，不过，把我所有的果子摘下来卖掉，你不就有钱了？”男孩十分激动，他摘下所有的果子，高高兴兴地走了。然后，男孩好久都没有来。大树很伤心。 有一天，男孩终于来了，大树兴奋地邀他一起玩。男孩说：“不行，我没有时间，我要替家里干活呢，我们需要一幢房子，你能帮忙吗？”“我没有房子。”大树说，“不过你可以把我的树枝统统砍下来，拿去搭房子。”于是男孩砍下所有的树枝，高高兴兴地运走去盖房子。看到男孩高兴大树好快乐。从此，男孩又不来了。大树再次陷入孤单和悲伤之中。一年夏天，男孩回来了，大树太快乐了：“来呀！孩子，来和我玩呀。”男孩却说：“我心情不好，一天天老了，我要扬帆出海，轻松一下，你能给我一艘船吗？”大树说：“把我的树干砍去，拿去做船吧！”于是男孩砍下了她的树干，造了条船，然后驾船走了，很久都没有回来。大树好快乐……但不是真的。 许多年过去，男孩终于回来，大树说：“对不起，孩子，我已经没有东西可以给你了，我的果子没了。”男孩说：“我的牙都掉了，吃不了苹果了。”大树又说：“我再没有树干，让你爬上来了。”男孩说：“我太老了，爬不动了。”“我再也没有什么给得出手了….只剩下枯死下去的老根。”树流着泪说。男孩说：“这么多年过去了，现在我感到累了，什么也不想要，只要一个休息的地方。”“好啊！老根是最适合坐下来休息的，来啊，坐下来和我一起休息吧！”男孩坐下来，大树高兴得流下了眼泪……这就是我们每个人的故事。这棵树就是我们的父母。小时候，我们喜欢和爸爸妈妈玩……长大后，我们就离开他们，只在需要什么东西或者遇到麻烦的时候，才回到他们身边。无论如何，父母永远都在那儿，倾其所有使你快乐。你可能认为这个男孩对树很残酷，但这就是我们每个人对待父母的方式。人生确实如此，请朋友们珍惜与父母在一起的时间！因为：树欲静而风不止，子欲养而亲不待。]]></content>
      <categories>
        <category>live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[小故事-孩子教育]]></title>
    <url>%2F2017%2F08%2F10%2Flive%2F%E7%94%B7%E5%AD%A9%E6%95%99%E8%82%B2%2F</url>
    <content type="text"><![CDATA[男孩教育一个爸爸告诉儿子：顶撞妈妈是有条件的·····有这么一个故事，妈妈们看完很是欣慰，爸爸们看完沉默发出了，孩子们看了懂事了很多···故事是这样的：有一次已经读高中的儿子因为妈妈总是唠叨，不耐烦的顶撞了母亲，母亲气得半死。当晚，父亲便约儿子一起出门散步。两人走了好久，父亲说道，顶撞妈妈时，下列的事任选一样，做到后，才有顶撞的权利！ ● 连续3个月每吃完一餐就须催吐(孕吐) ● 乳头被别人吸到破皮达一个月(喂奶) ● 肚子塞一颗篮球达10个月(怀孕) ● 接受皮鞭抽打达48小时(生小孩) ● 10个月不能喝冰水、咖啡、茶 ● 5个月睡觉不能翻身 ● 10个月不能出游远行，不能跑跳 ● 10个月不能生病，实在要是病了，生病不能吃药 ● 生完孩子把屎把尿一个月 ● 晚上睡觉每二个小时起床一次，清醒30分钟达一个月。一直到要进家门口时，父亲拍拍儿子的肩膀，以男人对男人的语气说:“等一下进去时，给我女人一点面子！”儿子惊讶于老爸用哥儿们的语气对他说话，并因男人跟男人之间的义气，从此对母亲毕恭毕敬的。看完这个故事，想起一个高中同学他说：有一次顶撞母亲，父亲把他从椅子上踹下来，斥责他：你妈是我捧在手心的宝，我呵护她，照顾她，对她轻声细语，你凭什么对他大声喊叫！我的同学再也不敢顶撞母亲了。这么多年来有谁会忍受着一辈子付出没有回报的？恐怕除了父母没有别人了吧？我们平时总是抱怨自己没有好背景，好父母，可生活在物质条件比父母强百倍的我们为什么不努力拼搏一把，成为父母的骄傲呢？ 需要教给孩子Grit坚毅、Zest激情、Self-control自制力、Optimism乐观态度、Gratitude感恩精神、Social intelligence社交智力、Curiosity好奇心 表达方式 [该做什么]，而非[不要做什么] 语言引动，动作也要跟上 有仪式感的阐述规则]]></content>
      <categories>
        <category>live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[小故事-读书无用论]]></title>
    <url>%2F2017%2F08%2F10%2Flive%2F%E4%B8%8A%E4%BA%86985%E3%80%81211%E6%89%8D%E7%9F%A5%E9%81%93%EF%BC%8C%E8%AF%BB%E4%B9%A6%E6%97%A0%E7%94%A8%E8%AE%BA%E9%83%BD%E6%98%AF%E9%AA%97%E4%BA%BA%E7%9A%84%2F</url>
    <content type="text"><![CDATA[上了985、211才知道，读书无用论都是骗人的01念高中时，常听班主任提起一位学姐，她几乎不跟周围的人说话，没什么朋友。 直到高考，她考了全省前十名。 市里去拍摄宣传时，发现她家中一贫如洗，父亲早就过世了，母亲还一直卧病在床。 高中为了省钱，她经常趁别人吃完饭离开后，去捡吃剩的馒头，一边捡一边吃。 那时候，有些高校会给优秀高考生数万元的金钱奖励。 她说，她高中三年拼命学习，目标就是能拿到那笔钱，这样她就自己赚够了学费，亲人就再也不能逼她赶紧辍学，早点嫁人。 “像我这种出身卑微的人，连任性的资格都没有，就害怕一停下来，就被别人狠狠地甩在后面。” 这让我想起云音乐的评论区常看到的一句话：我不敢倒下，因为身后空无一人。 知乎上有个提问：底层出身的孩子，假设当年你没能上 985 或者 211，你会损失和错过什么？ 什么是底层？ 就是除了你自己，你一无所有。而只能靠自己的人，连个性都是奢侈品。 02有人说，这是一个英雄不论出处的年代，也是一个英雄必论出处的年代。 龟兔赛跑，如果兔子一直在拼命跑，结果会怎么样？ 英国BBC曾拍摄纪录片，展现14个孩子，50年的人生轨迹。 7岁时，来自精英家庭的John和Andrew已经习惯了每天看《金融报》或《观察家》，而贫民窟孩子的理想，是能少罚站，少被打，吃饱饭。 50年后，几个精英家庭的孩子，上了好学校，找到好工作。 三个中产家庭的孩子，有一位成为精英，两个依旧中产。 而几个来自底层的孩子，包括他们的后代，依然常常与失业相伴。 知识改变命运背后，也是一场关于家庭的较量。 有钱的基础是，你家庭的资源、背景，加上你的努力和运气。但大多数人，不过是为了生计而出卖劳动的人。 纪录片中曾辍学的父母，没能力教孩子怎么学，因为穷，他们也没钱让别人来教，到后来，伦敦的孩子Tony也辍学了。 七岁的John和Andrew说自己每天都会读《金融时报》/《人生七年》 03人脉、财富、教育等资源，会父传子，子传孙。 据《中国家庭发展报告2015》，农村80%的留守儿童从没参加过课外辅导，在西部贫困农村，63%的学生甚至没有高中文凭。 中国校友网对全国各省级高考状元开展调查，发现在2007-2016年间，全国共有约837名高考状元。 其中，近五成状元父母是教师(35%)和工程师(12.6%)，近两成父母是公务员。 来自农村、经济状况欠佳家庭的状元所占比例在下降。 这种现象，就如同今年北京高考状元说的： 像我这种属于中产阶级家庭的孩子，还生在北京，所以在教育资源上享有得天独厚的条件，我在学习的时候，确实能走很多捷径。 状元身份的背后，一定付出了汗水，但这不是一个人的战斗，支撑他的还有良好的教育环境。 原生家庭对人的影响，真的太大了，有时你不得不承认：自己努力的天花板，不过是别人的起点。 条条大路通罗马，有人出生在罗马。 《北京爱情故事》里的石小猛，前期极尽努力，但在职场上依然被上司克扣，受尽欺负。 他在特别绝望的时候说： 人生就是一场比赛，可有的人连参赛资格都没有。确实，那些富家子弟手中的东西可能是我们一辈子也买不起的东西。我再努力再勤奋八百辈子，有用吗？没用，赶不上你一生下来，嘴里边含一把金钥匙，我呢，也别勤奋了，别努力了，我就吃吃斋，念念佛，找个好时候好地方，投个好胎，找个好爹。 人的每一种奢望都是设想“如何能付出最少而得到最多”，但这个世界上并不存在这种极端不公平的交易。 所以大学，起码提供给了底层可行的前进捷径，终其一生或许谈不上逆袭，但在人生的接力赛中，你是自己孩子的起点。 跨过这条千军万马的独木桥，以后的门票会越来越贵，你可能再也买不起入场券了。 剧中的石小猛/《北京爱情故事》 04为什么一定要上名校？ ● 一、你身边人的优秀程度，会影响你 过去20年来，北大先后有500余名保安考学深造，有的考上了研究生，当起大学老师。 每个学校都有保安，但为什么这种成群结队的考学行为，在名校发生的概率更大？媒体采访“北大保安第一人张俊成”的报道里，或许就藏着答案。 张俊成说，有次站岗，看到一位老人骑车过来，快到门岗前，老人下车，推车走过。 经过门岗时，老人点头跟他说：“你辛苦了”。 张俊成感到很受宠若惊，他问旁人，“这是谁？怎么这么尊重我们？” 别人告知，老人是北大校长。 在保安岗位上，张俊成也曾一度“迷失”，他说，“那个时候非常无知、愚昧”。 但他却得到了多位北大教授的热心帮助，在教授们的建议下，他才开始重新读书学习。 《精进》一书中谈到： 一个年轻人，进入一所不那么优秀的高校，对自己的标准会不由自主地降低以适应这个环境，减少自身与环境的冲突，而这种做法对他们的人生也许是致命的。 而在一片向上的氛围中，周围的人都在努力，自己也会用相对严格的标准来审视自己，不断自省，哪怕最后变不成最牛的，也可以优秀出众。 ● 二、名校的光环，是一种优秀的传递 当别人无法深入接触你时，你的头衔，外表等外在表现，往往决定了他们对你的看法。 大学生如同韭菜，收完一茬又会有一茬，已经不怎么新鲜了，在这种情况下，“名校”就是一道招牌。 稍微想一想就不难理解，亲戚家有孩子考上名校，周围人会口口相传，“谁家的孩子，上XX学校了！了不起！” 八竿子打不着的关系都要掰扯清楚，好像有了这层关系，自己的身价也能水涨船高。 名校在人心中的地位始终就不一般，它的声望是由多年来源源不断地人才输入和输出才形成的。所以HR选择名牌大学的求职者，成本无疑是最低的。 在他们看来，出身名校，起码意味着有智商或者有毅力，说到第一学历，古人也非常重视。 满清重臣左宗棠，举人出身，终其一生没也考中进士，这成了他永远的痛，甚至让他在宦海中饱受侮辱和曲折，后来他成了正一品，还不忘给自己弄一个荣誉进士的称号。 到了现在，国内大公司招聘时，几乎都会明确地写明岗位的学历要求，有些岗位要求至少是本科以上学历，有人说这是“歧视”。 关于“第一学历”，某社区曾发起过一次探讨，参与者各抒己见，其中被点赞最多的留言是这么说的： 国家队为什么要从省队里选运动员？我是全村跑步最快的为什么不能参加奥运会？第一学历不好有两个重要隐患， ● 1、过高地估计自己努力的价值和自身水平； ● 2、过低地估计科学研究的困难程度和世界的大小。 第一学历不能决定人一辈子，文凭也证明不了人的能力，但一些机会，在某些时候只留给有这张纸的人。 ● 三、人脉的扩张，是一个人能力与资源的扩张 好大学能带给你接触更广泛圈子的机会，人脉的扩张，也是一个人能力与资源的扩张。 有次和一位在创业的学长聊天，他说他现在的团队，基本是研究生时期的同学，并且导师觉得他的项目前景不错，主动帮他做宣传。 当年北大毕业的陆步轩，以卖猪肉为生，全国哗然。 别人只看到才子卖猪肉的不光鲜，但陆的校友陈生却注意到：一个档口，自己一天只能卖1.2头猪，陆步轩却能卖出12头，简直太牛逼了。 陈生邀请他做品牌顾问，两人合作成立“屠夫学校”，养殖土猪，后来，他们开了几百家连锁店，陈生身家也过百亿。 不光是创业上的资源，为什么名校毕业生大多能找到外人眼中不错的工作？ 除了本身能力问题，校友的作用也很明显。 比如前辈在大型企业上班，那你进入他的圈子实习和求职的机会，一定会比其他学校的学生多。 ● 四、薪酬待遇 更功利性一些，如果你以赚更多钱为目标，学历绝对是决定因素之一，在薪资这件事上，国内外都保持了一致。 福利待遇好的公务员事业编国企员工等岗位，都有硬性的比较高的学历要求。 2010年中央国家行政机关对学历的要求，硕士以上学历的职位有294个，占职位总数的54.55%；而专科学历可以报考的职位只有1个。 ● 五、受教育程度低的人，通过嫁娶来改变命运越来越难 从相同或相似的阶层群体中挑选配偶，这种门当户对式婚姻匹配，被称为同质婚。反之，跨越社会等级、社会群体壁垒的婚姻，为异质婚。 据《中国家庭发展报告2016》，20世纪80年代以后，相同和相近文化程度的婚姻匹配比例显著提高。 “男高女低”的异质婚配模式减少，受教育程度低的人群更加难以通过婚姻实现社会流动。 女性选择比自己受教育程度高的男性的空间越来越小，越来越集中在比自己仅仅高一个层次的梯度中选择，也就是现在鸡汤文常说的“你是谁，就会嫁给谁”。 而受教育程度低的农村男性，在择偶时面临更为严峻的困境。01一张高校文凭，不能确保让人站上顶峰，却会让大多数人免于跌落谷底。 那些说它“没用”的人，不过是一直处在谷底上方，但这绝不等同于“谷底”不存在。 曾看到一位网友的跟贴，他说： 其实我也没高考，也没读过大学，现在过得也不错，但这是我几年来起早摸黑努力得到的结果。不可以说读书无用论，其实读好大学，人生肯定会有个好的起点，更好地认识世界。 学识影响眼界，眼界决定格局，而格局影响人一生。 有句被说过无数遍的话：最怕你一生碌碌无为，还安慰自己平凡可贵。 还没高调的资格呢，就嚷嚷着要低调，还没活明白呢就开始说去伪存真，这是一种最损己不利人的行为，自己活得假，别人看着也特别累。 读书是一生的事，不是什么时候要用到了，我们才去学什么。 刘媛媛演讲“寒门贵子”/《超级演说家》 刘媛媛在《超级演说家》中曾发表过这样一段演说： 有些人出生就含着金钥匙，有些人出生连爸妈都没有，人生跟人生是没有可比性的，我们的人生是怎么样，完全决定于自己的感受。 你一辈子都在感受抱怨，那你的一生就是抱怨的一生； 你一辈子都在感受感动，那你的一生就是感动的一生； 你一辈子都立志于改变这个社会，那你的一生就是斗士的一生。 这世界就是，一些人总在昼夜不停地运转，而另外一些人，起床就发现世界已经变了。]]></content>
      <categories>
        <category>live</category>
      </categories>
  </entry>
</search>
